{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"mobilenetv2_celeba_v2","provenance":[],"authorship_tag":"ABX9TyMxzcKDQqipIOdtaf5MJVC6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"T2IvTdM77oii","executionInfo":{"status":"ok","timestamp":1604598660039,"user_tz":-480,"elapsed":10401,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"2492af87-4539-4262-a26c-5f81c0a8e0bd","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install wandb -qqq"],"execution_count":1,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.8MB 9.0MB/s \n","\u001b[K     |████████████████████████████████| 133kB 53.1MB/s \n","\u001b[K     |████████████████████████████████| 102kB 14.0MB/s \n","\u001b[K     |████████████████████████████████| 102kB 13.5MB/s \n","\u001b[K     |████████████████████████████████| 163kB 49.3MB/s \n","\u001b[K     |████████████████████████████████| 71kB 10.2MB/s \n","\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GqyCQTBf8gqO","executionInfo":{"status":"ok","timestamp":1604598730733,"user_tz":-480,"elapsed":57058,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"8cec0e89-139b-4ab6-8746-b83870296837","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5CBaAkSa7_IT","executionInfo":{"status":"ok","timestamp":1604604811024,"user_tz":-480,"elapsed":5906338,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"52dfeadf-f187-445e-e732-e00dfdb53c90","colab":{"base_uri":"https://localhost:8080/"}},"source":["import wandb\n","from wandb.keras import WandbCallback\n","import numpy as np\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import pandas as pd\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","\n","# GPU Configuration\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","defaults = {\n","    'epochs': 15,\n","    'batch_size': 128,\n","    'fc1_num_neurons': 1024,\n","    'fc2_num_neurons': 512,\n","    'fc3_num_neurons': 256,\n","    'seed': 7,\n","    'learning_rate': 1e-3,\n","    'optimizer': 'adam',\n","    'hidden_activation': 'relu',\n","    'output_activation': 'sigmoid',\n","    'loss_function': 'binary_crossentropy',\n","    'metrics': ['accuracy'],\n","}\n","\n","WANDB_API_KEY=\"aa601783a9e0b5f4bde1480428fb5318ad3dc0f2\"\n","wandb.init(config=defaults, resume=True, name='MN-V2', project='cz4042', notes='image size 112')\n","config = wandb.config\n","\n","# Load dataset as dataframe\n","df = pd.read_csv(\"/content/drive/My Drive/Y4 Sem 1/NN Project/aligned_gender.txt\", sep='\\t')\n","train_df, test_df = train_test_split(df, test_size=0.2)\n","train_df['datadir'] = '/content/drive/My Drive/Y4 Sem 1/NN Project/' + train_df['datadir'].astype(str)\n","test_df['datadir'] = '/content/drive/My Drive/Y4 Sem 1/NN Project/' + test_df['datadir'].astype(str)\n","\n","# Load images into keras image generator \n","datagen_train = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",")\n","datagen_test = ImageDataGenerator(\n","    preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",")\n","\n","train_generator = datagen_train.flow_from_dataframe(\n","    dataframe=train_df,\n","    x_col='datadir',\n","    y_col='gender',\n","    batch_size=config.batch_size,\n","    seed=config.seed,\n","    shuffle=True,\n","    class_mode='raw',\n","    target_size=(224,224),\n",")\n","\n","test_generator = datagen_test.flow_from_dataframe(\n","    dataframe=test_df,\n","    x_col='datadir',\n","    y_col='gender',\n","    batch_size=config.batch_size,\n","    seed=config.seed,\n","    shuffle=True,\n","    class_mode='raw',\n","    target_size=(224,224),\n",")\n","\n","# Define model\n","mobile_net_v2 = tf.keras.applications.MobileNetV2(\n","    include_top=False,\n","    pooling='avg',\n","    weights=None,\n","    input_shape=(224,224,3),\n",")\n","\n","# Set mobilenetv2 to true (to match CelebA architecture, we turn it off later)\n","mobile_net_v2.trainable = True\n","\n","fc1 = tf.keras.layers.Dense(\n","    config.fc1_num_neurons,\n","    activation=config.hidden_activation,\n",")\n","\n","fc2 = tf.keras.layers.Dense(\n","    config.fc2_num_neurons,\n","    activation=config.hidden_activation,\n",")\n","\n","fc3 = tf.keras.layers.Dense(\n","    config.fc2_num_neurons,\n","    activation=config.hidden_activation,\n",")\n","\n","model = tf.keras.models.Sequential([\n","    mobile_net_v2,\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.BatchNormalization(),\n","    fc1,\n","    tf.keras.layers.BatchNormalization(),\n","    fc2,\n","    tf.keras.layers.BatchNormalization(),\n","    fc3,\n","    tf.keras.layers.BatchNormalization(),\n","    tf.keras.layers.Dense(1, activation=config.output_activation),\n","])\n","# Load model weights\n","model.load_weights('/content/drive/My Drive/Y4 Sem 1/NN Project/model_celeba_resized.h5')\n","# Set trainable weights to false again\n","mobile_net_v2.trainable = False\n","model.summary()\n","\n","# Compile model \n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(learning_rate=config.learning_rate),\n","    loss=config.loss_function,\n","    metrics=config.metrics,\n",")\n","\n","model.fit(\n","    train_generator,\n","    validation_data=test_generator,\n","    epochs=config.epochs,\n","    callbacks=[WandbCallback()],\n",")\n","model.save_weights('pretrained_adience_v2.h5') \n","# run.finish()"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Found 9755 validated image filenames.\n","Found 2439 validated image filenames.\n","Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","mobilenetv2_1.00_224 (Functi (None, 1280)              2257984   \n","_________________________________________________________________\n","flatten (Flatten)            (None, 1280)              0         \n","_________________________________________________________________\n","batch_normalization (BatchNo (None, 1280)              5120      \n","_________________________________________________________________\n","dense (Dense)                (None, 1024)              1311744   \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 1024)              4096      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 512)               524800    \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 512)               262656    \n","_________________________________________________________________\n","batch_normalization_3 (Batch (None, 512)               2048      \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 513       \n","=================================================================\n","Total params: 4,371,009\n","Trainable params: 2,106,369\n","Non-trainable params: 2,264,640\n","_________________________________________________________________\n","Epoch 1/15\n","77/77 [==============================] - 3761s 49s/step - loss: 1.1301 - accuracy: 0.5748 - val_loss: 0.6915 - val_accuracy: 0.5047\n","Epoch 2/15\n","77/77 [==============================] - 146s 2s/step - loss: 0.6648 - accuracy: 0.6084 - val_loss: 0.6682 - val_accuracy: 0.5949\n","Epoch 3/15\n","77/77 [==============================] - 146s 2s/step - loss: 0.6592 - accuracy: 0.6159 - val_loss: 0.6535 - val_accuracy: 0.6236\n","Epoch 4/15\n","77/77 [==============================] - 146s 2s/step - loss: 0.6534 - accuracy: 0.6215 - val_loss: 0.6504 - val_accuracy: 0.6302\n","Epoch 5/15\n","77/77 [==============================] - 146s 2s/step - loss: 0.6499 - accuracy: 0.6242 - val_loss: 0.6450 - val_accuracy: 0.6384\n","Epoch 6/15\n","77/77 [==============================] - 146s 2s/step - loss: 0.6457 - accuracy: 0.6376 - val_loss: 0.6502 - val_accuracy: 0.6273\n","Epoch 7/15\n","77/77 [==============================] - 145s 2s/step - loss: 0.6448 - accuracy: 0.6325 - val_loss: 0.6448 - val_accuracy: 0.6335\n","Epoch 8/15\n","77/77 [==============================] - 144s 2s/step - loss: 0.6409 - accuracy: 0.6352 - val_loss: 0.6408 - val_accuracy: 0.6429\n","Epoch 9/15\n","77/77 [==============================] - 143s 2s/step - loss: 0.6382 - accuracy: 0.6383 - val_loss: 0.6398 - val_accuracy: 0.6363\n","Epoch 10/15\n","77/77 [==============================] - 144s 2s/step - loss: 0.6379 - accuracy: 0.6414 - val_loss: 0.6519 - val_accuracy: 0.6326\n","Epoch 11/15\n","77/77 [==============================] - 144s 2s/step - loss: 0.6341 - accuracy: 0.6445 - val_loss: 0.6522 - val_accuracy: 0.6220\n","Epoch 12/15\n","77/77 [==============================] - 143s 2s/step - loss: 0.6359 - accuracy: 0.6434 - val_loss: 0.6396 - val_accuracy: 0.6400\n","Epoch 13/15\n","77/77 [==============================] - 144s 2s/step - loss: 0.6359 - accuracy: 0.6443 - val_loss: 0.6570 - val_accuracy: 0.6261\n","Epoch 14/15\n","77/77 [==============================] - 143s 2s/step - loss: 0.6331 - accuracy: 0.6396 - val_loss: 0.6524 - val_accuracy: 0.6207\n","Epoch 15/15\n","77/77 [==============================] - 143s 2s/step - loss: 0.6290 - accuracy: 0.6453 - val_loss: 0.6380 - val_accuracy: 0.6371\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"awQnqIQh9pLL"},"source":[""],"execution_count":null,"outputs":[]}]}