{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Q1a_CharCNN","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyObWZ+8TLQMwWgTxlm2HpOv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gb812AAeIveu"},"source":["# Mount Drive"]},{"cell_type":"code","metadata":{"id":"MsObL7B7Siou","executionInfo":{"status":"ok","timestamp":1605173871859,"user_tz":-480,"elapsed":42803,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"50277ec7-313a-43c3-f300-c61968aa956d","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mz9wasoAI1Og"},"source":["# Install Weights and Biases"]},{"cell_type":"code","metadata":{"id":"NdaTK82wnP1b","executionInfo":{"status":"ok","timestamp":1605173883131,"user_tz":-480,"elapsed":14351,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"c8fe952c-30e5-4bc3-d19c-3808199c830d","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install wandb -qqq"],"execution_count":3,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.8MB 11.3MB/s \n","\u001b[K     |████████████████████████████████| 102kB 10.2MB/s \n","\u001b[K     |████████████████████████████████| 133kB 40.6MB/s \n","\u001b[K     |████████████████████████████████| 163kB 16.7MB/s \n","\u001b[K     |████████████████████████████████| 102kB 10.4MB/s \n","\u001b[K     |████████████████████████████████| 71kB 7.8MB/s \n","\u001b[?25h  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VTbKeQ4wI8VC"},"source":["# Run Model"]},{"cell_type":"code","metadata":{"id":"9oGQD0F_dqYS","executionInfo":{"status":"ok","timestamp":1605173883132,"user_tz":-480,"elapsed":12689,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}}},"source":["# Preprocessing functions\n","def vocabulary(strings):\n","    chars = sorted(list(set(list(''.join(strings)))))\n","    char_to_ix = { ch:i for i,ch in enumerate(chars) }\n","    vocab_size = len(chars)\n","    return vocab_size, char_to_ix\n","\n","def preprocess(strings, char_to_ix, MAX_LENGTH):\n","    data_chars = [list(d.lower()) for _, d in enumerate(strings)]\n","    for i, d in enumerate(data_chars):\n","        if len(d)>MAX_LENGTH:\n","            d = d[:MAX_LENGTH]\n","        elif len(d) < MAX_LENGTH:\n","            d += [' '] * (MAX_LENGTH - len(d))\n","            \n","    data_ids = np.zeros([len(data_chars), MAX_LENGTH], dtype=np.int64)\n","    for i in range(len(data_chars)):\n","        for j in range(MAX_LENGTH):\n","            data_ids[i, j] = char_to_ix[data_chars[i][j]]\n","    return np.array(data_ids)\n","\n","def read_data_chars():\n","    x_train, y_train, x_test, y_test = [], [], [], []\n","    cop = re.compile(\"[^a-z^A-Z^0-9^,^.^' ']\")\n","    with open('/content/drive/My Drive/Neural Networks/NN_Assignment_2/Part_B_Text_Classification/train_medium.csv', encoding='utf-8') as filex:\n","        reader = csv.reader(filex)\n","        for row in reader:\n","            data = cop.sub(\"\", row[1])\n","            x_train.append(data)\n","            y_train.append(int(row[0]))\n","\n","    with open('/content/drive/My Drive/Neural Networks/NN_Assignment_2/Part_B_Text_Classification/test_medium.csv', encoding='utf-8') as filex:\n","        reader = csv.reader(filex)\n","        for row in reader:\n","            data = cop.sub(\"\", row[1])\n","            x_test.append(data)\n","            y_test.append(int(row[0]))\n","\n","\n","    vocab_size, char_to_ix = vocabulary(x_train+x_test)\n","    x_train = preprocess(x_train, char_to_ix, 100)\n","    y_train = np.array(y_train)\n","    x_test = preprocess(x_test, char_to_ix, 100)\n","    y_test = np.array(y_test)\n","\n","    x_train = tf.constant(x_train, dtype=tf.int64)\n","    y_train = tf.constant(y_train, dtype=tf.int64)\n","    x_test = tf.constant(x_test, dtype=tf.int64)\n","    y_test = tf.constant(y_test, dtype=tf.int64)\n","\n","    return x_train, y_train, x_test, y_test"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ugg05UW4QnW8","executionInfo":{"status":"ok","timestamp":1605173989437,"user_tz":-480,"elapsed":117930,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"906cfdfd-a6f5-43f5-d4bf-c1ae6e0fa6bb","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import wandb\n","from wandb.keras import WandbCallback\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import Model, layers\n","import csv\n","import re\n","\n","# Hyperparameters\n","defaults = {\n","    'num_filters_c1' : 10,\n","    'num_filters_c2' : 10,\n","    'wsize_c1' : (20, 256),\n","    'wsize_c2' :(20, 1),\n","    'batch_size' : 128,\n","    'epochs' : 250,\n","    'lr' : 0.01,\n","    'Dropout' : 'No'\n","}\n","\n","# Initiate wandb\n","wandb.init(config=defaults, resume=True, name='Q1a V5', project='NNA2 Part B Checks')\n","config = wandb.config\n","\n","# Fix lucky seed!\n","seed = 7\n","tf.random.set_seed(seed)\n","np.random.seed(seed)\n","\n","# Train test split\n","x_train, y_train, x_test, y_test = read_data_chars()\n","\n","# Use `tf.data` to batch and shuffle the dataset:\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (x_train, y_train)).shuffle(10000).batch(config.batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(config.batch_size)\n","\n","# Define model\n","tf.keras.backend.set_floatx('float32')\n","class CharCNN(Model):\n","    def __init__(self, vocab_size=256):\n","        super(CharCNN, self).__init__()\n","        self.vocab_size = vocab_size\n","        # Weight variables and RNN cell\n","        self.conv1 = layers.Conv2D(config.num_filters_c1, config.wsize_c1, padding='valid', activation='relu')\n","        self.pool1 = layers.MaxPool2D(pool_size=4, strides=2, padding='same')\n","        self.conv2 = layers.Conv2D(config.num_filters_c2, config.wsize_c2, padding='valid', activation='relu')\n","        self.pool2 = layers.MaxPool2D(pool_size=4, strides=2, padding='same')\n","        self.flatten = layers.Flatten()\n","        self.dense = layers.Dense(15, activation='softmax')\n","\n","    def call(self, x, drop_rate=0.5):\n","        x = tf.one_hot(x, 256)\n","        x = x[..., tf.newaxis] \n","        x = self.conv1(x)\n","        x = self.pool1(x)\n","        x = self.conv2(x)\n","        x = self.pool2(x)\n","        x = self.flatten(x)\n","        # x = tf.nn.dropout(x, drop_rate)\n","        logits = self.dense(x)\n","        return logits\n","\n","model = CharCNN(256)\n","\n","# Choose optimizer and loss function\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n","opt = tf.keras.optimizers.SGD(learning_rate=config.lr)\n","\n","# Compile model\n","model.compile(\n","    optimizer=opt,\n","    loss=loss_object,\n","    metrics=['accuracy'],\n",")\n","\n","# Train model\n","model.fit(\n","    train_ds,\n","    validation_data=test_ds,\n","    epochs=config.epochs,\n","    callbacks=[WandbCallback()],\n","    )\n"],"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"],"name":"stderr"},{"output_type":"stream","text":["wandb: Paste an API key from your profile and hit enter: ··········\n"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.10<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">Q1a V4</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/todayisagreatday/NNA2%20Part%20B%20Checks\" target=\"_blank\">https://wandb.ai/todayisagreatday/NNA2%20Part%20B%20Checks</a><br/>\n","                Run page: <a href=\"https://wandb.ai/todayisagreatday/NNA2%20Part%20B%20Checks/runs/1ci33qbz\" target=\"_blank\">https://wandb.ai/todayisagreatday/NNA2%20Part%20B%20Checks/runs/1ci33qbz</a><br/>\n","                Run data is saved locally in <code>/content/wandb/run-20201112_093824-1ci33qbz</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/250\n","44/44 [==============================] - ETA: 0s - loss: 2.7034 - accuracy: 0.0702"],"name":"stdout"},{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Can't save model, h5py returned error: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\n"],"name":"stderr"},{"output_type":"stream","text":["44/44 [==============================] - 0s 11ms/step - loss: 2.7034 - accuracy: 0.0702 - val_loss: 2.6977 - val_accuracy: 0.0757\n","Epoch 2/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.6939 - accuracy: 0.0763 - val_loss: 2.6902 - val_accuracy: 0.0700\n","Epoch 3/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.6858 - accuracy: 0.0784 - val_loss: 2.6831 - val_accuracy: 0.0743\n","Epoch 4/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.6782 - accuracy: 0.0820 - val_loss: 2.6761 - val_accuracy: 0.0900\n","Epoch 5/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.6708 - accuracy: 0.0905 - val_loss: 2.6695 - val_accuracy: 0.1057\n","Epoch 6/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.6636 - accuracy: 0.0950 - val_loss: 2.6628 - val_accuracy: 0.1129\n","Epoch 7/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.6564 - accuracy: 0.1116 - val_loss: 2.6559 - val_accuracy: 0.1071\n","Epoch 8/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.6490 - accuracy: 0.1255 - val_loss: 2.6489 - val_accuracy: 0.1129\n","Epoch 9/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.6413 - accuracy: 0.1336 - val_loss: 2.6416 - val_accuracy: 0.1271\n","Epoch 10/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.6332 - accuracy: 0.1427 - val_loss: 2.6339 - val_accuracy: 0.1371\n","Epoch 11/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.6246 - accuracy: 0.1489 - val_loss: 2.6257 - val_accuracy: 0.1500\n","Epoch 12/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.6155 - accuracy: 0.1602 - val_loss: 2.6170 - val_accuracy: 0.1571\n","Epoch 13/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.6058 - accuracy: 0.1709 - val_loss: 2.6076 - val_accuracy: 0.1629\n","Epoch 14/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.5950 - accuracy: 0.1784 - val_loss: 2.5974 - val_accuracy: 0.1786\n","Epoch 15/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.5834 - accuracy: 0.2002 - val_loss: 2.5866 - val_accuracy: 0.1786\n","Epoch 16/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.5706 - accuracy: 0.2041 - val_loss: 2.5740 - val_accuracy: 0.1871\n","Epoch 17/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.5564 - accuracy: 0.2223 - val_loss: 2.5601 - val_accuracy: 0.1971\n","Epoch 18/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.5406 - accuracy: 0.2441 - val_loss: 2.5445 - val_accuracy: 0.2257\n","Epoch 19/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.5225 - accuracy: 0.2650 - val_loss: 2.5268 - val_accuracy: 0.2343\n","Epoch 20/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.5020 - accuracy: 0.2780 - val_loss: 2.5063 - val_accuracy: 0.2429\n","Epoch 21/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.4785 - accuracy: 0.2955 - val_loss: 2.4823 - val_accuracy: 0.2643\n","Epoch 22/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.4508 - accuracy: 0.3043 - val_loss: 2.4555 - val_accuracy: 0.2557\n","Epoch 23/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.4187 - accuracy: 0.3039 - val_loss: 2.4228 - val_accuracy: 0.2914\n","Epoch 24/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.3815 - accuracy: 0.3200 - val_loss: 2.3870 - val_accuracy: 0.2929\n","Epoch 25/250\n","44/44 [==============================] - 0s 6ms/step - loss: 2.3382 - accuracy: 0.3304 - val_loss: 2.3429 - val_accuracy: 0.3157\n","Epoch 26/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.2903 - accuracy: 0.3393 - val_loss: 2.2952 - val_accuracy: 0.3171\n","Epoch 27/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.2370 - accuracy: 0.3482 - val_loss: 2.2444 - val_accuracy: 0.3357\n","Epoch 28/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.1807 - accuracy: 0.3639 - val_loss: 2.1903 - val_accuracy: 0.3414\n","Epoch 29/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.1221 - accuracy: 0.3686 - val_loss: 2.1403 - val_accuracy: 0.3600\n","Epoch 30/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.0637 - accuracy: 0.3752 - val_loss: 2.0822 - val_accuracy: 0.3700\n","Epoch 31/250\n","44/44 [==============================] - 0s 5ms/step - loss: 2.0056 - accuracy: 0.3936 - val_loss: 2.0332 - val_accuracy: 0.3514\n","Epoch 32/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.9503 - accuracy: 0.4082 - val_loss: 1.9802 - val_accuracy: 0.3586\n","Epoch 33/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.8959 - accuracy: 0.4112 - val_loss: 1.9302 - val_accuracy: 0.3757\n","Epoch 34/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.8455 - accuracy: 0.4221 - val_loss: 1.8935 - val_accuracy: 0.4029\n","Epoch 35/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.7965 - accuracy: 0.4379 - val_loss: 1.8392 - val_accuracy: 0.3986\n","Epoch 36/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.7501 - accuracy: 0.4454 - val_loss: 1.7987 - val_accuracy: 0.4086\n","Epoch 37/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.7064 - accuracy: 0.4554 - val_loss: 1.7588 - val_accuracy: 0.4243\n","Epoch 38/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.6639 - accuracy: 0.4663 - val_loss: 1.7206 - val_accuracy: 0.4214\n","Epoch 39/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.6265 - accuracy: 0.4754 - val_loss: 1.6984 - val_accuracy: 0.4500\n","Epoch 40/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.5883 - accuracy: 0.4905 - val_loss: 1.6531 - val_accuracy: 0.4614\n","Epoch 41/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.5500 - accuracy: 0.4988 - val_loss: 1.6317 - val_accuracy: 0.4329\n","Epoch 42/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.5208 - accuracy: 0.5086 - val_loss: 1.6009 - val_accuracy: 0.4543\n","Epoch 43/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.4874 - accuracy: 0.5170 - val_loss: 1.5687 - val_accuracy: 0.4843\n","Epoch 44/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.4624 - accuracy: 0.5216 - val_loss: 1.5454 - val_accuracy: 0.4814\n","Epoch 45/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.4303 - accuracy: 0.5268 - val_loss: 1.5190 - val_accuracy: 0.5014\n","Epoch 46/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.4054 - accuracy: 0.5400 - val_loss: 1.4932 - val_accuracy: 0.5086\n","Epoch 47/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.3792 - accuracy: 0.5466 - val_loss: 1.4719 - val_accuracy: 0.5200\n","Epoch 48/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.3573 - accuracy: 0.5530 - val_loss: 1.4651 - val_accuracy: 0.5029\n","Epoch 49/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.3325 - accuracy: 0.5659 - val_loss: 1.4418 - val_accuracy: 0.5129\n","Epoch 50/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.3126 - accuracy: 0.5691 - val_loss: 1.4612 - val_accuracy: 0.5057\n","Epoch 51/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.2973 - accuracy: 0.5716 - val_loss: 1.4143 - val_accuracy: 0.5114\n","Epoch 52/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.2703 - accuracy: 0.5796 - val_loss: 1.4119 - val_accuracy: 0.5229\n","Epoch 53/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.2551 - accuracy: 0.5870 - val_loss: 1.3709 - val_accuracy: 0.5314\n","Epoch 54/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.2351 - accuracy: 0.5961 - val_loss: 1.3552 - val_accuracy: 0.5357\n","Epoch 55/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.2192 - accuracy: 0.5971 - val_loss: 1.3749 - val_accuracy: 0.5186\n","Epoch 56/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.2063 - accuracy: 0.6075 - val_loss: 1.3527 - val_accuracy: 0.5357\n","Epoch 57/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.1958 - accuracy: 0.6016 - val_loss: 1.3177 - val_accuracy: 0.5471\n","Epoch 58/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.1752 - accuracy: 0.6089 - val_loss: 1.3438 - val_accuracy: 0.5443\n","Epoch 59/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.1626 - accuracy: 0.6154 - val_loss: 1.3129 - val_accuracy: 0.5343\n","Epoch 60/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.1456 - accuracy: 0.6230 - val_loss: 1.2954 - val_accuracy: 0.5386\n","Epoch 61/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.1353 - accuracy: 0.6211 - val_loss: 1.2685 - val_accuracy: 0.5657\n","Epoch 62/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.1182 - accuracy: 0.6309 - val_loss: 1.2716 - val_accuracy: 0.5457\n","Epoch 63/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.1084 - accuracy: 0.6323 - val_loss: 1.2640 - val_accuracy: 0.5757\n","Epoch 64/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.0855 - accuracy: 0.6452 - val_loss: 1.2688 - val_accuracy: 0.5486\n","Epoch 65/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.0805 - accuracy: 0.6438 - val_loss: 1.2594 - val_accuracy: 0.5714\n","Epoch 66/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.0558 - accuracy: 0.6529 - val_loss: 1.2942 - val_accuracy: 0.5329\n","Epoch 67/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.0640 - accuracy: 0.6496 - val_loss: 1.2340 - val_accuracy: 0.5643\n","Epoch 68/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.0594 - accuracy: 0.6488 - val_loss: 1.2170 - val_accuracy: 0.5814\n","Epoch 69/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.0356 - accuracy: 0.6579 - val_loss: 1.2338 - val_accuracy: 0.5843\n","Epoch 70/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.0216 - accuracy: 0.6682 - val_loss: 1.2089 - val_accuracy: 0.5886\n","Epoch 71/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.0046 - accuracy: 0.6637 - val_loss: 1.2175 - val_accuracy: 0.5829\n","Epoch 72/250\n","44/44 [==============================] - 0s 6ms/step - loss: 1.0108 - accuracy: 0.6702 - val_loss: 1.1814 - val_accuracy: 0.6029\n","Epoch 73/250\n","44/44 [==============================] - 0s 5ms/step - loss: 1.0007 - accuracy: 0.6655 - val_loss: 1.1939 - val_accuracy: 0.6000\n","Epoch 74/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9817 - accuracy: 0.6720 - val_loss: 1.1960 - val_accuracy: 0.5843\n","Epoch 75/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9713 - accuracy: 0.6800 - val_loss: 1.2080 - val_accuracy: 0.5857\n","Epoch 76/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9739 - accuracy: 0.6762 - val_loss: 1.2606 - val_accuracy: 0.5714\n","Epoch 77/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.9722 - accuracy: 0.6762 - val_loss: 1.1720 - val_accuracy: 0.5986\n","Epoch 78/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9592 - accuracy: 0.6880 - val_loss: 1.1642 - val_accuracy: 0.5957\n","Epoch 79/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.9359 - accuracy: 0.6920 - val_loss: 1.1452 - val_accuracy: 0.6143\n","Epoch 80/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9613 - accuracy: 0.6780 - val_loss: 1.2415 - val_accuracy: 0.5929\n","Epoch 81/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9217 - accuracy: 0.7018 - val_loss: 1.2288 - val_accuracy: 0.5771\n","Epoch 82/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.9020 - accuracy: 0.7043 - val_loss: 1.1530 - val_accuracy: 0.5986\n","Epoch 83/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9047 - accuracy: 0.7025 - val_loss: 1.1454 - val_accuracy: 0.6143\n","Epoch 84/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8999 - accuracy: 0.7034 - val_loss: 1.1267 - val_accuracy: 0.6043\n","Epoch 85/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.9057 - accuracy: 0.6945 - val_loss: 1.1851 - val_accuracy: 0.6014\n","Epoch 86/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.8826 - accuracy: 0.7080 - val_loss: 1.1938 - val_accuracy: 0.6000\n","Epoch 87/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8758 - accuracy: 0.7109 - val_loss: 1.1063 - val_accuracy: 0.6214\n","Epoch 88/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8703 - accuracy: 0.7154 - val_loss: 1.1566 - val_accuracy: 0.6171\n","Epoch 89/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8583 - accuracy: 0.7164 - val_loss: 1.1136 - val_accuracy: 0.6143\n","Epoch 90/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.8374 - accuracy: 0.7287 - val_loss: 1.1003 - val_accuracy: 0.6214\n","Epoch 91/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8528 - accuracy: 0.7125 - val_loss: 1.5502 - val_accuracy: 0.5157\n","Epoch 92/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.8820 - accuracy: 0.7071 - val_loss: 1.1087 - val_accuracy: 0.6100\n","Epoch 93/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8418 - accuracy: 0.7279 - val_loss: 1.0935 - val_accuracy: 0.6386\n","Epoch 94/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8344 - accuracy: 0.7250 - val_loss: 1.1358 - val_accuracy: 0.6100\n","Epoch 95/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8320 - accuracy: 0.7259 - val_loss: 1.1007 - val_accuracy: 0.6200\n","Epoch 96/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.8433 - accuracy: 0.7221 - val_loss: 1.2929 - val_accuracy: 0.5786\n","Epoch 97/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.8223 - accuracy: 0.7300 - val_loss: 1.1256 - val_accuracy: 0.6286\n","Epoch 98/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7930 - accuracy: 0.7423 - val_loss: 1.0663 - val_accuracy: 0.6429\n","Epoch 99/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7929 - accuracy: 0.7362 - val_loss: 1.0940 - val_accuracy: 0.6300\n","Epoch 100/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7720 - accuracy: 0.7446 - val_loss: 1.1017 - val_accuracy: 0.6271\n","Epoch 101/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.8056 - accuracy: 0.7320 - val_loss: 1.1411 - val_accuracy: 0.6086\n","Epoch 102/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7828 - accuracy: 0.7466 - val_loss: 1.0840 - val_accuracy: 0.6471\n","Epoch 103/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.7445 - accuracy: 0.7630 - val_loss: 1.1596 - val_accuracy: 0.6100\n","Epoch 104/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7695 - accuracy: 0.7486 - val_loss: 1.1054 - val_accuracy: 0.6186\n","Epoch 105/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.7846 - accuracy: 0.7414 - val_loss: 1.1366 - val_accuracy: 0.6143\n","Epoch 106/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.8036 - accuracy: 0.7320 - val_loss: 1.0612 - val_accuracy: 0.6500\n","Epoch 107/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.7330 - accuracy: 0.7636 - val_loss: 1.0450 - val_accuracy: 0.6443\n","Epoch 108/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7576 - accuracy: 0.7480 - val_loss: 1.0796 - val_accuracy: 0.6314\n","Epoch 109/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.7196 - accuracy: 0.7621 - val_loss: 1.0884 - val_accuracy: 0.6271\n","Epoch 110/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7209 - accuracy: 0.7688 - val_loss: 1.1264 - val_accuracy: 0.6357\n","Epoch 111/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7166 - accuracy: 0.7705 - val_loss: 1.1054 - val_accuracy: 0.6357\n","Epoch 112/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7240 - accuracy: 0.7586 - val_loss: 1.0877 - val_accuracy: 0.6371\n","Epoch 113/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7686 - accuracy: 0.7418 - val_loss: 1.1046 - val_accuracy: 0.6214\n","Epoch 114/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6913 - accuracy: 0.7764 - val_loss: 1.0981 - val_accuracy: 0.6400\n","Epoch 115/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6862 - accuracy: 0.7807 - val_loss: 1.1059 - val_accuracy: 0.6286\n","Epoch 116/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6857 - accuracy: 0.7761 - val_loss: 1.0462 - val_accuracy: 0.6657\n","Epoch 117/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7151 - accuracy: 0.7677 - val_loss: 1.1945 - val_accuracy: 0.6071\n","Epoch 118/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6852 - accuracy: 0.7755 - val_loss: 1.0900 - val_accuracy: 0.6571\n","Epoch 119/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7039 - accuracy: 0.7723 - val_loss: 1.1759 - val_accuracy: 0.6314\n","Epoch 120/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6793 - accuracy: 0.7761 - val_loss: 1.0965 - val_accuracy: 0.6386\n","Epoch 121/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6995 - accuracy: 0.7739 - val_loss: 1.0522 - val_accuracy: 0.6586\n","Epoch 122/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6463 - accuracy: 0.7952 - val_loss: 1.3109 - val_accuracy: 0.6043\n","Epoch 123/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6502 - accuracy: 0.7902 - val_loss: 1.1034 - val_accuracy: 0.6443\n","Epoch 124/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6562 - accuracy: 0.7875 - val_loss: 1.1613 - val_accuracy: 0.6457\n","Epoch 125/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6702 - accuracy: 0.7804 - val_loss: 1.1230 - val_accuracy: 0.6429\n","Epoch 126/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6766 - accuracy: 0.7727 - val_loss: 1.2394 - val_accuracy: 0.6100\n","Epoch 127/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6562 - accuracy: 0.7825 - val_loss: 1.0520 - val_accuracy: 0.6700\n","Epoch 128/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.7921 - val_loss: 1.0883 - val_accuracy: 0.6514\n","Epoch 129/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6361 - accuracy: 0.7946 - val_loss: 1.0444 - val_accuracy: 0.6457\n","Epoch 130/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6093 - accuracy: 0.8075 - val_loss: 1.0719 - val_accuracy: 0.6600\n","Epoch 131/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6226 - accuracy: 0.7989 - val_loss: 1.0742 - val_accuracy: 0.6400\n","Epoch 132/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.7108 - accuracy: 0.7655 - val_loss: 1.0316 - val_accuracy: 0.6614\n","Epoch 133/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6111 - accuracy: 0.8016 - val_loss: 1.0501 - val_accuracy: 0.6500\n","Epoch 134/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.7998 - val_loss: 1.1508 - val_accuracy: 0.6457\n","Epoch 135/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.8080 - val_loss: 1.1224 - val_accuracy: 0.6543\n","Epoch 136/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5990 - accuracy: 0.8084 - val_loss: 1.2911 - val_accuracy: 0.5957\n","Epoch 137/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5902 - accuracy: 0.8152 - val_loss: 1.0444 - val_accuracy: 0.6514\n","Epoch 138/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5974 - accuracy: 0.8064 - val_loss: 1.0639 - val_accuracy: 0.6657\n","Epoch 139/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5764 - accuracy: 0.8163 - val_loss: 1.1464 - val_accuracy: 0.6400\n","Epoch 140/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.6320 - accuracy: 0.7920 - val_loss: 1.0397 - val_accuracy: 0.6571\n","Epoch 141/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6192 - accuracy: 0.7971 - val_loss: 1.2706 - val_accuracy: 0.5957\n","Epoch 142/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5813 - accuracy: 0.8143 - val_loss: 1.0759 - val_accuracy: 0.6543\n","Epoch 143/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5806 - accuracy: 0.8166 - val_loss: 1.2808 - val_accuracy: 0.6114\n","Epoch 144/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5930 - accuracy: 0.8004 - val_loss: 1.1318 - val_accuracy: 0.6343\n","Epoch 145/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.8293 - val_loss: 1.1009 - val_accuracy: 0.6514\n","Epoch 146/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5489 - accuracy: 0.8236 - val_loss: 1.1016 - val_accuracy: 0.6443\n","Epoch 147/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5949 - accuracy: 0.8079 - val_loss: 1.1268 - val_accuracy: 0.6614\n","Epoch 148/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5645 - accuracy: 0.8236 - val_loss: 1.2944 - val_accuracy: 0.6129\n","Epoch 149/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5774 - accuracy: 0.8111 - val_loss: 1.1517 - val_accuracy: 0.6286\n","Epoch 150/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5221 - accuracy: 0.8395 - val_loss: 1.0459 - val_accuracy: 0.6543\n","Epoch 151/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5291 - accuracy: 0.8330 - val_loss: 1.1950 - val_accuracy: 0.6271\n","Epoch 152/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5613 - accuracy: 0.8177 - val_loss: 1.0634 - val_accuracy: 0.6557\n","Epoch 153/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.5262 - accuracy: 0.8350 - val_loss: 1.0374 - val_accuracy: 0.6643\n","Epoch 154/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5043 - accuracy: 0.8411 - val_loss: 1.1004 - val_accuracy: 0.6586\n","Epoch 155/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6716 - accuracy: 0.7948 - val_loss: 1.1108 - val_accuracy: 0.6529\n","Epoch 156/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5102 - accuracy: 0.8379 - val_loss: 1.1026 - val_accuracy: 0.6400\n","Epoch 157/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.8377 - val_loss: 1.0857 - val_accuracy: 0.6557\n","Epoch 158/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.8468 - val_loss: 1.1827 - val_accuracy: 0.6543\n","Epoch 159/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5040 - accuracy: 0.8448 - val_loss: 1.1451 - val_accuracy: 0.6557\n","Epoch 160/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.8438 - val_loss: 1.0516 - val_accuracy: 0.6586\n","Epoch 161/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4880 - accuracy: 0.8500 - val_loss: 1.1130 - val_accuracy: 0.6600\n","Epoch 162/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5058 - accuracy: 0.8461 - val_loss: 1.0669 - val_accuracy: 0.6614\n","Epoch 163/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.5129 - accuracy: 0.8304 - val_loss: 1.0755 - val_accuracy: 0.6586\n","Epoch 164/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4720 - accuracy: 0.8546 - val_loss: 1.1652 - val_accuracy: 0.6471\n","Epoch 165/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4898 - accuracy: 0.8402 - val_loss: 1.0787 - val_accuracy: 0.6614\n","Epoch 166/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.8477 - val_loss: 1.1036 - val_accuracy: 0.6571\n","Epoch 167/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.8343 - val_loss: 1.0823 - val_accuracy: 0.6629\n","Epoch 168/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4788 - accuracy: 0.8480 - val_loss: 1.1295 - val_accuracy: 0.6514\n","Epoch 169/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4973 - accuracy: 0.8404 - val_loss: 1.0806 - val_accuracy: 0.6629\n","Epoch 170/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4828 - accuracy: 0.8459 - val_loss: 1.0637 - val_accuracy: 0.6686\n","Epoch 171/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.8557 - val_loss: 1.0921 - val_accuracy: 0.6529\n","Epoch 172/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4381 - accuracy: 0.8645 - val_loss: 1.0846 - val_accuracy: 0.6643\n","Epoch 173/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4768 - accuracy: 0.8500 - val_loss: 1.0783 - val_accuracy: 0.6686\n","Epoch 174/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.8636 - val_loss: 1.2109 - val_accuracy: 0.6371\n","Epoch 175/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.4791 - accuracy: 0.8471 - val_loss: 1.1276 - val_accuracy: 0.6543\n","Epoch 176/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.4584 - accuracy: 0.8539 - val_loss: 1.2875 - val_accuracy: 0.6186\n","Epoch 177/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4622 - accuracy: 0.8509 - val_loss: 1.0795 - val_accuracy: 0.6686\n","Epoch 178/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4273 - accuracy: 0.8664 - val_loss: 1.1314 - val_accuracy: 0.6614\n","Epoch 179/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8712 - val_loss: 1.1687 - val_accuracy: 0.6400\n","Epoch 180/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8625 - val_loss: 1.0889 - val_accuracy: 0.6629\n","Epoch 181/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4179 - accuracy: 0.8736 - val_loss: 1.0945 - val_accuracy: 0.6657\n","Epoch 182/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4288 - accuracy: 0.8662 - val_loss: 1.1201 - val_accuracy: 0.6586\n","Epoch 183/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4729 - accuracy: 0.8498 - val_loss: 1.1198 - val_accuracy: 0.6600\n","Epoch 184/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4198 - accuracy: 0.8687 - val_loss: 1.1283 - val_accuracy: 0.6500\n","Epoch 185/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4058 - accuracy: 0.8721 - val_loss: 1.1314 - val_accuracy: 0.6471\n","Epoch 186/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4044 - accuracy: 0.8773 - val_loss: 1.1516 - val_accuracy: 0.6571\n","Epoch 187/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.4163 - accuracy: 0.8720 - val_loss: 1.3296 - val_accuracy: 0.6257\n","Epoch 188/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.8612 - val_loss: 1.1532 - val_accuracy: 0.6543\n","Epoch 189/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.4259 - accuracy: 0.8668 - val_loss: 1.1595 - val_accuracy: 0.6500\n","Epoch 190/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.8405 - val_loss: 1.1756 - val_accuracy: 0.6529\n","Epoch 191/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4182 - accuracy: 0.8711 - val_loss: 1.1982 - val_accuracy: 0.6686\n","Epoch 192/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3933 - accuracy: 0.8782 - val_loss: 1.1725 - val_accuracy: 0.6500\n","Epoch 193/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3881 - accuracy: 0.8807 - val_loss: 1.1683 - val_accuracy: 0.6643\n","Epoch 194/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4075 - accuracy: 0.8668 - val_loss: 1.2053 - val_accuracy: 0.6414\n","Epoch 195/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4147 - accuracy: 0.8673 - val_loss: 1.1773 - val_accuracy: 0.6471\n","Epoch 196/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3839 - accuracy: 0.8820 - val_loss: 1.1266 - val_accuracy: 0.6629\n","Epoch 197/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3763 - accuracy: 0.8855 - val_loss: 1.1251 - val_accuracy: 0.6671\n","Epoch 198/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3793 - accuracy: 0.8854 - val_loss: 1.3160 - val_accuracy: 0.6414\n","Epoch 199/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3898 - accuracy: 0.8770 - val_loss: 1.1229 - val_accuracy: 0.6800\n","Epoch 200/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.3849 - accuracy: 0.8839 - val_loss: 1.1216 - val_accuracy: 0.6671\n","Epoch 201/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.8602 - val_loss: 1.4276 - val_accuracy: 0.6329\n","Epoch 202/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.6759 - accuracy: 0.8043 - val_loss: 1.1255 - val_accuracy: 0.6629\n","Epoch 203/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3542 - accuracy: 0.8984 - val_loss: 1.1355 - val_accuracy: 0.6614\n","Epoch 204/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3538 - accuracy: 0.8957 - val_loss: 1.1498 - val_accuracy: 0.6729\n","Epoch 205/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3567 - accuracy: 0.8946 - val_loss: 1.1524 - val_accuracy: 0.6743\n","Epoch 206/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.3828 - accuracy: 0.8779 - val_loss: 1.2022 - val_accuracy: 0.6614\n","Epoch 207/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3545 - accuracy: 0.8921 - val_loss: 1.1402 - val_accuracy: 0.6643\n","Epoch 208/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3471 - accuracy: 0.8982 - val_loss: 1.1738 - val_accuracy: 0.6757\n","Epoch 209/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3439 - accuracy: 0.8964 - val_loss: 1.3051 - val_accuracy: 0.6457\n","Epoch 210/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3468 - accuracy: 0.8938 - val_loss: 1.2030 - val_accuracy: 0.6486\n","Epoch 211/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.3546 - accuracy: 0.8905 - val_loss: 1.3554 - val_accuracy: 0.6271\n","Epoch 212/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3326 - accuracy: 0.9045 - val_loss: 1.1527 - val_accuracy: 0.6700\n","Epoch 213/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3240 - accuracy: 0.9071 - val_loss: 1.1828 - val_accuracy: 0.6586\n","Epoch 214/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3453 - accuracy: 0.8959 - val_loss: 1.1378 - val_accuracy: 0.6786\n","Epoch 215/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3505 - accuracy: 0.8923 - val_loss: 1.1585 - val_accuracy: 0.6643\n","Epoch 216/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.3319 - accuracy: 0.9027 - val_loss: 1.2628 - val_accuracy: 0.6429\n","Epoch 217/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3369 - accuracy: 0.8970 - val_loss: 1.1841 - val_accuracy: 0.6643\n","Epoch 218/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3270 - accuracy: 0.8991 - val_loss: 1.1976 - val_accuracy: 0.6700\n","Epoch 219/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3360 - accuracy: 0.8989 - val_loss: 1.1963 - val_accuracy: 0.6686\n","Epoch 220/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3180 - accuracy: 0.9057 - val_loss: 1.2253 - val_accuracy: 0.6743\n","Epoch 221/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3175 - accuracy: 0.9059 - val_loss: 1.1901 - val_accuracy: 0.6571\n","Epoch 222/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3092 - accuracy: 0.9105 - val_loss: 1.2689 - val_accuracy: 0.6543\n","Epoch 223/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3194 - accuracy: 0.9048 - val_loss: 1.2088 - val_accuracy: 0.6771\n","Epoch 224/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3079 - accuracy: 0.9127 - val_loss: 1.1843 - val_accuracy: 0.6657\n","Epoch 225/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3058 - accuracy: 0.9112 - val_loss: 1.2306 - val_accuracy: 0.6686\n","Epoch 226/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3001 - accuracy: 0.9136 - val_loss: 1.1842 - val_accuracy: 0.6686\n","Epoch 227/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3061 - accuracy: 0.9096 - val_loss: 1.2070 - val_accuracy: 0.6671\n","Epoch 228/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3006 - accuracy: 0.9130 - val_loss: 1.2540 - val_accuracy: 0.6543\n","Epoch 229/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3255 - accuracy: 0.9004 - val_loss: 1.4826 - val_accuracy: 0.6086\n","Epoch 230/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3010 - accuracy: 0.9095 - val_loss: 1.1962 - val_accuracy: 0.6829\n","Epoch 231/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.3736 - accuracy: 0.8807 - val_loss: 1.2950 - val_accuracy: 0.6400\n","Epoch 232/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2813 - accuracy: 0.9220 - val_loss: 1.1912 - val_accuracy: 0.6743\n","Epoch 233/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.9220 - val_loss: 1.2568 - val_accuracy: 0.6614\n","Epoch 234/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2972 - accuracy: 0.9102 - val_loss: 1.2854 - val_accuracy: 0.6686\n","Epoch 235/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2844 - accuracy: 0.9164 - val_loss: 1.2937 - val_accuracy: 0.6557\n","Epoch 236/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2937 - accuracy: 0.9132 - val_loss: 1.2201 - val_accuracy: 0.6700\n","Epoch 237/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2720 - accuracy: 0.9255 - val_loss: 1.5141 - val_accuracy: 0.6100\n","Epoch 238/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.3013 - accuracy: 0.9105 - val_loss: 1.2533 - val_accuracy: 0.6600\n","Epoch 239/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2846 - accuracy: 0.9193 - val_loss: 1.2046 - val_accuracy: 0.6700\n","Epoch 240/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2909 - accuracy: 0.9168 - val_loss: 1.2174 - val_accuracy: 0.6714\n","Epoch 241/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2569 - accuracy: 0.9309 - val_loss: 1.2268 - val_accuracy: 0.6686\n","Epoch 242/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2777 - accuracy: 0.9202 - val_loss: 1.2797 - val_accuracy: 0.6686\n","Epoch 243/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2778 - accuracy: 0.9161 - val_loss: 1.2204 - val_accuracy: 0.6743\n","Epoch 244/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2681 - accuracy: 0.9223 - val_loss: 1.4348 - val_accuracy: 0.6543\n","Epoch 245/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2746 - accuracy: 0.9161 - val_loss: 1.3146 - val_accuracy: 0.6614\n","Epoch 246/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2603 - accuracy: 0.9295 - val_loss: 1.2489 - val_accuracy: 0.6657\n","Epoch 247/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2626 - accuracy: 0.9248 - val_loss: 1.2313 - val_accuracy: 0.6729\n","Epoch 248/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.2658 - accuracy: 0.9236 - val_loss: 1.2266 - val_accuracy: 0.6771\n","Epoch 249/250\n","44/44 [==============================] - 0s 6ms/step - loss: 0.5401 - accuracy: 0.8611 - val_loss: 1.2300 - val_accuracy: 0.6743\n","Epoch 250/250\n","44/44 [==============================] - 0s 5ms/step - loss: 0.2476 - accuracy: 0.9332 - val_loss: 1.3193 - val_accuracy: 0.6643\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f61cb47fb70>"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"id":"C-60Y8FPS7Ki"},"source":[""],"execution_count":null,"outputs":[]}]}