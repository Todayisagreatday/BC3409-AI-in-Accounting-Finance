{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"obj_recognition_test","provenance":[],"authorship_tag":"ABX9TyOq563oArMZL6OvngMT48iL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d456744376464eb2941928f4c737fbf5":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","state":{"_view_name":"VBoxView","_dom_classes":[],"_model_name":"VBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_f027047a6c044615aebb2967611285a7","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7ff1ba841f2e445c90200e4f980efe5e","IPY_MODEL_59351f21587b44388a764f8a1a4f9c14"]}},"f027047a6c044615aebb2967611285a7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7ff1ba841f2e445c90200e4f980efe5e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","state":{"_view_name":"LabelView","style":"IPY_MODEL_e7e57c0784e5446a8cc2b04349c8a52e","_dom_classes":[],"description":"","_model_name":"LabelModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 3.06MB of 3.06MB uploaded (0.00MB deduped)\r","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a1896aaf8e84faea6bc74e0f60c3b90"}},"59351f21587b44388a764f8a1a4f9c14":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_78857cd25f0a41b3813cdcb9365d3b05","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d78cfbf876054697b19ac9c4c01bda52"}},"e7e57c0784e5446a8cc2b04349c8a52e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"0a1896aaf8e84faea6bc74e0f60c3b90":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78857cd25f0a41b3813cdcb9365d3b05":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d78cfbf876054697b19ac9c4c01bda52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"sYJ7Hmdsa6tQ","executionInfo":{"status":"ok","timestamp":1604586429531,"user_tz":-480,"elapsed":56563,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"8b969254-df5a-4f16-e74c-6a5388cb0304","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ie0kUXgLcblx","executionInfo":{"status":"ok","timestamp":1604586442723,"user_tz":-480,"elapsed":9698,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"d45b6542-3a31-4bdc-ec68-3b5ab903f36b","colab":{"base_uri":"https://localhost:8080/"}},"source":["!pip install wandb -qqq"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 1.8MB 12.3MB/s \n","\u001b[K     |████████████████████████████████| 102kB 13.9MB/s \n","\u001b[K     |████████████████████████████████| 163kB 60.7MB/s \n","\u001b[K     |████████████████████████████████| 102kB 14.4MB/s \n","\u001b[K     |████████████████████████████████| 133kB 55.3MB/s \n","\u001b[K     |████████████████████████████████| 71kB 11.6MB/s \n","\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sCRipGnHbaBj","executionInfo":{"status":"error","timestamp":1604590146474,"user_tz":-480,"elapsed":273940,"user":{"displayName":"Kenneth Ng","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgKwZnZ2dHsOvtWnGFQksMtsfZc2QK_Fv86edRayg=s64","userId":"07556015887030206568"}},"outputId":"cdaee16f-24a5-440f-ee01-1b9af45a2169","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["d456744376464eb2941928f4c737fbf5","f027047a6c044615aebb2967611285a7","7ff1ba841f2e445c90200e4f980efe5e","59351f21587b44388a764f8a1a4f9c14","e7e57c0784e5446a8cc2b04349c8a52e","0a1896aaf8e84faea6bc74e0f60c3b90","78857cd25f0a41b3813cdcb9365d3b05","d78cfbf876054697b19ac9c4c01bda52"]}},"source":["import wandb\n","from wandb.keras import WandbCallback\n","import os\n","import pickle\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras import layers, models, optimizers, preprocessing, optimizers, callbacks\n","\n","WANDB_API_KEY='47cec5f0053a625595783afd29aca8c472d6c144' \n","# GPU Configuration\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        print(e)\n","\n","# Function to load data file \n","def load_data(file):\n","    with open(file, 'rb') as fo:\n","        try:\n","            samples = pickle.load(fo)\n","        except UnicodeDecodeError:  # python 3.x\n","            fo.seek(0)\n","            samples = pickle.load(fo, encoding='latin1')\n","\n","    data, labels = samples['data'], samples['labels']\n","\n","    data = np.array(data, dtype=np.float32) / 255\n","    labels = np.array(labels, dtype=np.int32)\n","    return data, labels\n","\n","# Define model \n","def make_model(num_ch_c1, num_ch_c2):\n","    \n","    model = models.Sequential()\n","    model.add(layers.Reshape(target_shape=(32, 32, 3), input_shape=(3072,)))\n","    model.add(layers.Conv2D(num_ch_c1, kernel_size=9, activation='relu', input_shape=(None, None, 3), padding='valid'))\n","    model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n","    model.add(layers.Conv2D(num_ch_c2, kernel_size=5, activation='relu', padding='valid'))\n","    model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n","    model.add(layers.Flatten())\n","    model.add(layers.Dense(300))\n","    model.add(layers.Dense(10, input_shape=(300,)))\n","    return model\n","\n","\n","def main():\n","    # Fix lucky seed!\n","    seed = 7\n","    np.random.seed(seed)\n","    tf.random.set_seed(seed)\n","\n","    # Hyperparameters\n","    defaults=dict(\n","    num_ch_c1 = 50, \n","    num_ch_c2 = 60,\n","    epochs = 1000,\n","    batch_size = 128,\n","    learning_rate = 1e-4,\n","    optimizer = 'SGD',\n","    dropout_layer_1 = 'No',\n","    dropout_layer_2 = 'No',\n","    )\n","    \n","    # Initiate wandb project \n","    wandb.init(config=defaults, resume=True, name='Test Model', project='NNA2 Test Runs')\n","    config = wandb.config\n","\n","    # Call model and define loss function\n","    model = make_model(config.num_ch_c1, config.num_ch_c2)\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","    # Choose optimizer\n","    if(config.optimizer == 'SGD'):\n","        SGD = optimizers.SGD(learning_rate=config.learning_rate)\n","        opt = SGD\n","    elif(config.optimizer == 'Adam'):\n","        Adam = optimizers.Adam(learning_rate=config.learning_rate)\n","        opt = Adam\n","    else:\n","        RMSprop = optimizers.RMSprop(learning_rate=config.learning_rate)\n","        opt = RMSprop\n","\n","    # Load training and test data\n","    x_train, y_train = load_data('/content/drive/My Drive/Neural Networks/NN_Assignment_2/Part_A_Object_Recognition/data_batch_1')\n","    x_test, y_test = load_data('/content/drive/My Drive/Neural Networks/NN_Assignment_2/Part_A_Object_Recognition/test_batch_trim')\n","\n","    # Compile and fit data\n","    model.compile(optimizer=opt, loss=loss, metrics='accuracy')\n","    model.fit(x_train, y_train,\n","                batch_size=config.batch_size,\n","                epochs=config.epochs,\n","                shuffle=True,\n","                validation_data=(x_test, y_test),\n","                callbacks=[WandbCallback()]\n","                )\n","if __name__ == '__main__':\n","    main()\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["1 Physical GPUs, 1 Logical GPUs\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["<br/>Waiting for W&B process to finish, PID 3628<br/>Program ended successfully."],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d456744376464eb2941928f4c737fbf5","version_minor":0,"version_major":2},"text/plain":["VBox(children=(Label(value=' 1.47MB of 1.47MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find user logs for this run at: <code>wandb/run-20201105_151033-1p9wte3b/logs/debug.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Find internal logs for this run at: <code>wandb/run-20201105_151033-1p9wte3b/logs/debug-internal.log</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run summary:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>999</td></tr><tr><td>loss</td><td>1.41064</td></tr><tr><td>accuracy</td><td>0.5119</td></tr><tr><td>val_loss</td><td>1.54656</td></tr><tr><td>val_accuracy</td><td>0.4695</td></tr><tr><td>_step</td><td>999</td></tr><tr><td>_runtime</td><td>540</td></tr><tr><td>_timestamp</td><td>1604589576</td></tr><tr><td>best_val_loss</td><td>1.50786</td></tr><tr><td>best_epoch</td><td>996</td></tr></table>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["<h3>Run history:</h3><br/><style>\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n","    </style><table class=\"wandb\">\n","<tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>█▇▇▆▅▅▅▄▄▄▄▄▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▃▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇████████</td></tr><tr><td>val_loss</td><td>█▇▆▆▅▅▄▄▄▄▄▃▃▃▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▄▅▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇██▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_runtime</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr></table><br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                    <br/>Synced <strong style=\"color:#cdcd00\">Test Model</strong>: <a href=\"https://wandb.ai/todayisagreatday/NNA2%20Test%20Runs/runs/1p9wte3b\" target=\"_blank\">https://wandb.ai/todayisagreatday/NNA2%20Test%20Runs/runs/1p9wte3b</a><br/>\n","                "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/html":["\n","                Tracking run with wandb version 0.10.9<br/>\n","                Syncing run <strong style=\"color:#cdcd00\">Test Model</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n","                Project page: <a href=\"https://wandb.ai/todayisagreatday/NNA2%20Test%20Runs\" target=\"_blank\">https://wandb.ai/todayisagreatday/NNA2%20Test%20Runs</a><br/>\n","                Run page: <a href=\"https://wandb.ai/todayisagreatday/NNA2%20Test%20Runs/runs/1b2c89hw\" target=\"_blank\">https://wandb.ai/todayisagreatday/NNA2%20Test%20Runs/runs/1b2c89hw</a><br/>\n","                Run data is saved locally in <code>wandb/run-20201105_152432-1b2c89hw</code><br/><br/>\n","            "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch 1/1000\n","79/79 [==============================] - 1s 11ms/step - loss: 2.3040 - accuracy: 0.1261 - val_loss: 2.2913 - val_accuracy: 0.1290\n","Epoch 2/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.2890 - accuracy: 0.1258 - val_loss: 2.2823 - val_accuracy: 0.1255\n","Epoch 3/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.2805 - accuracy: 0.1299 - val_loss: 2.2752 - val_accuracy: 0.1350\n","Epoch 4/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.2729 - accuracy: 0.1431 - val_loss: 2.2679 - val_accuracy: 0.1485\n","Epoch 5/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 2.2654 - accuracy: 0.1567 - val_loss: 2.2607 - val_accuracy: 0.1685\n","Epoch 6/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.2575 - accuracy: 0.1741 - val_loss: 2.2522 - val_accuracy: 0.1830\n","Epoch 7/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.2490 - accuracy: 0.1916 - val_loss: 2.2433 - val_accuracy: 0.2015\n","Epoch 8/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.2399 - accuracy: 0.2067 - val_loss: 2.2339 - val_accuracy: 0.1895\n","Epoch 9/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.2302 - accuracy: 0.2045 - val_loss: 2.2243 - val_accuracy: 0.2240\n","Epoch 10/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.2199 - accuracy: 0.2316 - val_loss: 2.2129 - val_accuracy: 0.2305\n","Epoch 11/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.2084 - accuracy: 0.2384 - val_loss: 2.2005 - val_accuracy: 0.2490\n","Epoch 12/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.1956 - accuracy: 0.2468 - val_loss: 2.1869 - val_accuracy: 0.2410\n","Epoch 13/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.1821 - accuracy: 0.2532 - val_loss: 2.1729 - val_accuracy: 0.2395\n","Epoch 14/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.1677 - accuracy: 0.2568 - val_loss: 2.1574 - val_accuracy: 0.2740\n","Epoch 15/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.1523 - accuracy: 0.2623 - val_loss: 2.1433 - val_accuracy: 0.2720\n","Epoch 16/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.1368 - accuracy: 0.2718 - val_loss: 2.1267 - val_accuracy: 0.2615\n","Epoch 17/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 2.1215 - accuracy: 0.2718 - val_loss: 2.1100 - val_accuracy: 0.2775\n","Epoch 18/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 2.1062 - accuracy: 0.2767 - val_loss: 2.0947 - val_accuracy: 0.2880\n","Epoch 19/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.0909 - accuracy: 0.2786 - val_loss: 2.0811 - val_accuracy: 0.2815\n","Epoch 20/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.0765 - accuracy: 0.2878 - val_loss: 2.0648 - val_accuracy: 0.3030\n","Epoch 21/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.0623 - accuracy: 0.2899 - val_loss: 2.0529 - val_accuracy: 0.2935\n","Epoch 22/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 2.0495 - accuracy: 0.2963 - val_loss: 2.0371 - val_accuracy: 0.3135\n","Epoch 23/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 2.0365 - accuracy: 0.2967 - val_loss: 2.0301 - val_accuracy: 0.2935\n","Epoch 24/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.0251 - accuracy: 0.2949 - val_loss: 2.0163 - val_accuracy: 0.3150\n","Epoch 25/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.0142 - accuracy: 0.3013 - val_loss: 2.0038 - val_accuracy: 0.2990\n","Epoch 26/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 2.0038 - accuracy: 0.3000 - val_loss: 1.9952 - val_accuracy: 0.3230\n","Epoch 27/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.9941 - accuracy: 0.3059 - val_loss: 1.9931 - val_accuracy: 0.2885\n","Epoch 28/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.9850 - accuracy: 0.3063 - val_loss: 1.9771 - val_accuracy: 0.3105\n","Epoch 29/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9766 - accuracy: 0.3064 - val_loss: 1.9762 - val_accuracy: 0.3030\n","Epoch 30/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.9686 - accuracy: 0.3064 - val_loss: 1.9724 - val_accuracy: 0.2875\n","Epoch 31/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9604 - accuracy: 0.3079 - val_loss: 1.9577 - val_accuracy: 0.2955\n","Epoch 32/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9523 - accuracy: 0.3165 - val_loss: 2.0030 - val_accuracy: 0.2635\n","Epoch 33/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.9466 - accuracy: 0.3137 - val_loss: 1.9414 - val_accuracy: 0.3270\n","Epoch 34/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9386 - accuracy: 0.3152 - val_loss: 1.9448 - val_accuracy: 0.3070\n","Epoch 35/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.9329 - accuracy: 0.3186 - val_loss: 1.9459 - val_accuracy: 0.3085\n","Epoch 36/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.9279 - accuracy: 0.3177 - val_loss: 1.9278 - val_accuracy: 0.3135\n","Epoch 37/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.9221 - accuracy: 0.3191 - val_loss: 1.9194 - val_accuracy: 0.3100\n","Epoch 38/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.9166 - accuracy: 0.3207 - val_loss: 1.9461 - val_accuracy: 0.3000\n","Epoch 39/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9110 - accuracy: 0.3248 - val_loss: 1.9261 - val_accuracy: 0.3075\n","Epoch 40/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9072 - accuracy: 0.3230 - val_loss: 1.9048 - val_accuracy: 0.3255\n","Epoch 41/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.9032 - accuracy: 0.3234 - val_loss: 1.9220 - val_accuracy: 0.2965\n","Epoch 42/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.8980 - accuracy: 0.3272 - val_loss: 1.9000 - val_accuracy: 0.3305\n","Epoch 43/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8934 - accuracy: 0.3270 - val_loss: 1.9271 - val_accuracy: 0.2925\n","Epoch 44/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8902 - accuracy: 0.3292 - val_loss: 1.8975 - val_accuracy: 0.3225\n","Epoch 45/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8863 - accuracy: 0.3308 - val_loss: 1.9223 - val_accuracy: 0.2965\n","Epoch 46/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8827 - accuracy: 0.3328 - val_loss: 1.8874 - val_accuracy: 0.3250\n","Epoch 47/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8778 - accuracy: 0.3329 - val_loss: 2.0684 - val_accuracy: 0.2635\n","Epoch 48/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8768 - accuracy: 0.3340 - val_loss: 1.8847 - val_accuracy: 0.3425\n","Epoch 49/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8709 - accuracy: 0.3363 - val_loss: 1.9180 - val_accuracy: 0.2945\n","Epoch 50/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8678 - accuracy: 0.3392 - val_loss: 1.8966 - val_accuracy: 0.3270\n","Epoch 51/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8651 - accuracy: 0.3396 - val_loss: 1.8802 - val_accuracy: 0.3305\n","Epoch 52/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8621 - accuracy: 0.3386 - val_loss: 1.8805 - val_accuracy: 0.3270\n","Epoch 53/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8607 - accuracy: 0.3425 - val_loss: 1.8859 - val_accuracy: 0.3275\n","Epoch 54/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.8560 - accuracy: 0.3405 - val_loss: 1.8792 - val_accuracy: 0.3195\n","Epoch 55/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8544 - accuracy: 0.3423 - val_loss: 1.8738 - val_accuracy: 0.3240\n","Epoch 56/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.8523 - accuracy: 0.3407 - val_loss: 1.8580 - val_accuracy: 0.3455\n","Epoch 57/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.8470 - accuracy: 0.3438 - val_loss: 1.8652 - val_accuracy: 0.3370\n","Epoch 58/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8446 - accuracy: 0.3425 - val_loss: 1.8621 - val_accuracy: 0.3325\n","Epoch 59/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8447 - accuracy: 0.3454 - val_loss: 1.8627 - val_accuracy: 0.3270\n","Epoch 60/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8393 - accuracy: 0.3445 - val_loss: 1.8515 - val_accuracy: 0.3345\n","Epoch 61/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8361 - accuracy: 0.3495 - val_loss: 1.8853 - val_accuracy: 0.3180\n","Epoch 62/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8343 - accuracy: 0.3471 - val_loss: 1.8831 - val_accuracy: 0.3295\n","Epoch 63/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8308 - accuracy: 0.3507 - val_loss: 1.8493 - val_accuracy: 0.3390\n","Epoch 64/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8300 - accuracy: 0.3532 - val_loss: 1.8363 - val_accuracy: 0.3490\n","Epoch 65/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8258 - accuracy: 0.3541 - val_loss: 1.8928 - val_accuracy: 0.3180\n","Epoch 66/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8251 - accuracy: 0.3493 - val_loss: 1.9050 - val_accuracy: 0.3055\n","Epoch 67/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8197 - accuracy: 0.3562 - val_loss: 1.8383 - val_accuracy: 0.3455\n","Epoch 68/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8189 - accuracy: 0.3567 - val_loss: 1.8973 - val_accuracy: 0.3070\n","Epoch 69/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.8167 - accuracy: 0.3551 - val_loss: 1.8304 - val_accuracy: 0.3420\n","Epoch 70/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8130 - accuracy: 0.3590 - val_loss: 1.8233 - val_accuracy: 0.3410\n","Epoch 71/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8105 - accuracy: 0.3630 - val_loss: 1.8252 - val_accuracy: 0.3465\n","Epoch 72/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8101 - accuracy: 0.3588 - val_loss: 1.8395 - val_accuracy: 0.3400\n","Epoch 73/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8062 - accuracy: 0.3607 - val_loss: 1.8573 - val_accuracy: 0.3435\n","Epoch 74/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.8056 - accuracy: 0.3627 - val_loss: 1.8074 - val_accuracy: 0.3625\n","Epoch 75/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.8008 - accuracy: 0.3604 - val_loss: 1.8514 - val_accuracy: 0.3380\n","Epoch 76/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7977 - accuracy: 0.3593 - val_loss: 1.8211 - val_accuracy: 0.3575\n","Epoch 77/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7982 - accuracy: 0.3643 - val_loss: 2.0400 - val_accuracy: 0.2735\n","Epoch 78/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7976 - accuracy: 0.3644 - val_loss: 1.8366 - val_accuracy: 0.3370\n","Epoch 79/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7909 - accuracy: 0.3655 - val_loss: 1.8266 - val_accuracy: 0.3390\n","Epoch 80/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7884 - accuracy: 0.3678 - val_loss: 1.8192 - val_accuracy: 0.3395\n","Epoch 81/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7880 - accuracy: 0.3653 - val_loss: 1.8145 - val_accuracy: 0.3555\n","Epoch 82/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7841 - accuracy: 0.3678 - val_loss: 1.8096 - val_accuracy: 0.3575\n","Epoch 83/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7830 - accuracy: 0.3694 - val_loss: 1.8180 - val_accuracy: 0.3530\n","Epoch 84/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7804 - accuracy: 0.3726 - val_loss: 1.8129 - val_accuracy: 0.3515\n","Epoch 85/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.7772 - accuracy: 0.3724 - val_loss: 1.8062 - val_accuracy: 0.3555\n","Epoch 86/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.7726 - accuracy: 0.3740 - val_loss: 1.7909 - val_accuracy: 0.3635\n","Epoch 87/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7729 - accuracy: 0.3746 - val_loss: 1.9681 - val_accuracy: 0.3030\n","Epoch 88/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7704 - accuracy: 0.3739 - val_loss: 1.8297 - val_accuracy: 0.3355\n","Epoch 89/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7684 - accuracy: 0.3706 - val_loss: 1.8037 - val_accuracy: 0.3485\n","Epoch 90/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7654 - accuracy: 0.3815 - val_loss: 1.8667 - val_accuracy: 0.3320\n","Epoch 91/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7650 - accuracy: 0.3711 - val_loss: 1.8750 - val_accuracy: 0.3340\n","Epoch 92/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7608 - accuracy: 0.3768 - val_loss: 1.7735 - val_accuracy: 0.3760\n","Epoch 93/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7585 - accuracy: 0.3792 - val_loss: 1.7893 - val_accuracy: 0.3730\n","Epoch 94/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7562 - accuracy: 0.3782 - val_loss: 1.8284 - val_accuracy: 0.3670\n","Epoch 95/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7565 - accuracy: 0.3788 - val_loss: 1.7735 - val_accuracy: 0.3745\n","Epoch 96/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7514 - accuracy: 0.3834 - val_loss: 1.8184 - val_accuracy: 0.3510\n","Epoch 97/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.7493 - accuracy: 0.3820 - val_loss: 1.7662 - val_accuracy: 0.3815\n","Epoch 98/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7449 - accuracy: 0.3835 - val_loss: 1.7591 - val_accuracy: 0.3780\n","Epoch 99/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.7427 - accuracy: 0.3852 - val_loss: 1.8440 - val_accuracy: 0.3485\n","Epoch 100/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7418 - accuracy: 0.3844 - val_loss: 1.8010 - val_accuracy: 0.3570\n","Epoch 101/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7381 - accuracy: 0.3834 - val_loss: 1.7900 - val_accuracy: 0.3740\n","Epoch 102/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7375 - accuracy: 0.3855 - val_loss: 1.7680 - val_accuracy: 0.3845\n","Epoch 103/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7344 - accuracy: 0.3850 - val_loss: 1.7633 - val_accuracy: 0.3740\n","Epoch 104/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7334 - accuracy: 0.3888 - val_loss: 1.8353 - val_accuracy: 0.3540\n","Epoch 105/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7315 - accuracy: 0.3871 - val_loss: 1.7524 - val_accuracy: 0.3705\n","Epoch 106/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7268 - accuracy: 0.3909 - val_loss: 1.7690 - val_accuracy: 0.3750\n","Epoch 107/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7265 - accuracy: 0.3891 - val_loss: 1.7916 - val_accuracy: 0.3540\n","Epoch 108/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7221 - accuracy: 0.3905 - val_loss: 1.7812 - val_accuracy: 0.3800\n","Epoch 109/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7231 - accuracy: 0.3890 - val_loss: 1.7368 - val_accuracy: 0.3840\n","Epoch 110/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7178 - accuracy: 0.3930 - val_loss: 1.7439 - val_accuracy: 0.3830\n","Epoch 111/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7164 - accuracy: 0.3924 - val_loss: 1.8334 - val_accuracy: 0.3560\n","Epoch 112/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7153 - accuracy: 0.3939 - val_loss: 1.7420 - val_accuracy: 0.3815\n","Epoch 113/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7117 - accuracy: 0.3938 - val_loss: 1.7408 - val_accuracy: 0.3785\n","Epoch 114/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7090 - accuracy: 0.3974 - val_loss: 1.7283 - val_accuracy: 0.3840\n","Epoch 115/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7068 - accuracy: 0.3949 - val_loss: 1.7300 - val_accuracy: 0.4020\n","Epoch 116/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7062 - accuracy: 0.3973 - val_loss: 1.8455 - val_accuracy: 0.3480\n","Epoch 117/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.7058 - accuracy: 0.3950 - val_loss: 1.7461 - val_accuracy: 0.3965\n","Epoch 118/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.7004 - accuracy: 0.4010 - val_loss: 1.7257 - val_accuracy: 0.3805\n","Epoch 119/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6997 - accuracy: 0.4000 - val_loss: 1.7218 - val_accuracy: 0.3975\n","Epoch 120/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6957 - accuracy: 0.4025 - val_loss: 1.7223 - val_accuracy: 0.3970\n","Epoch 121/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6930 - accuracy: 0.4041 - val_loss: 1.7334 - val_accuracy: 0.3835\n","Epoch 122/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6920 - accuracy: 0.4004 - val_loss: 1.7315 - val_accuracy: 0.3905\n","Epoch 123/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6899 - accuracy: 0.4026 - val_loss: 1.7203 - val_accuracy: 0.4065\n","Epoch 124/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6883 - accuracy: 0.4061 - val_loss: 1.7298 - val_accuracy: 0.3880\n","Epoch 125/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6860 - accuracy: 0.4015 - val_loss: 1.7557 - val_accuracy: 0.3645\n","Epoch 126/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6856 - accuracy: 0.4035 - val_loss: 1.7789 - val_accuracy: 0.3810\n","Epoch 127/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6825 - accuracy: 0.4093 - val_loss: 1.7179 - val_accuracy: 0.3960\n","Epoch 128/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6803 - accuracy: 0.4075 - val_loss: 1.9027 - val_accuracy: 0.3415\n","Epoch 129/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6800 - accuracy: 0.4072 - val_loss: 1.7154 - val_accuracy: 0.3930\n","Epoch 130/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6759 - accuracy: 0.4136 - val_loss: 1.7575 - val_accuracy: 0.3725\n","Epoch 131/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6730 - accuracy: 0.4093 - val_loss: 1.7405 - val_accuracy: 0.4025\n","Epoch 132/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6725 - accuracy: 0.4090 - val_loss: 1.7182 - val_accuracy: 0.3940\n","Epoch 133/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6691 - accuracy: 0.4116 - val_loss: 1.7329 - val_accuracy: 0.3890\n","Epoch 134/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6684 - accuracy: 0.4112 - val_loss: 1.7191 - val_accuracy: 0.4015\n","Epoch 135/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6643 - accuracy: 0.4153 - val_loss: 1.7627 - val_accuracy: 0.3675\n","Epoch 136/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6644 - accuracy: 0.4147 - val_loss: 1.6917 - val_accuracy: 0.4195\n","Epoch 137/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6612 - accuracy: 0.4160 - val_loss: 1.7073 - val_accuracy: 0.4015\n","Epoch 138/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6608 - accuracy: 0.4167 - val_loss: 1.7337 - val_accuracy: 0.3820\n","Epoch 139/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6578 - accuracy: 0.4153 - val_loss: 1.7037 - val_accuracy: 0.3940\n","Epoch 140/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6554 - accuracy: 0.4180 - val_loss: 1.7017 - val_accuracy: 0.3980\n","Epoch 141/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6570 - accuracy: 0.4189 - val_loss: 1.7195 - val_accuracy: 0.3940\n","Epoch 142/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6523 - accuracy: 0.4217 - val_loss: 1.7525 - val_accuracy: 0.3735\n","Epoch 143/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6498 - accuracy: 0.4221 - val_loss: 1.7401 - val_accuracy: 0.3865\n","Epoch 144/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6496 - accuracy: 0.4247 - val_loss: 1.6828 - val_accuracy: 0.4140\n","Epoch 145/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6460 - accuracy: 0.4197 - val_loss: 1.6822 - val_accuracy: 0.4230\n","Epoch 146/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6448 - accuracy: 0.4248 - val_loss: 1.6842 - val_accuracy: 0.4045\n","Epoch 147/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6445 - accuracy: 0.4200 - val_loss: 1.7098 - val_accuracy: 0.3935\n","Epoch 148/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6440 - accuracy: 0.4196 - val_loss: 1.6799 - val_accuracy: 0.4035\n","Epoch 149/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6387 - accuracy: 0.4269 - val_loss: 1.7369 - val_accuracy: 0.3805\n","Epoch 150/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6386 - accuracy: 0.4239 - val_loss: 1.6997 - val_accuracy: 0.3925\n","Epoch 151/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6384 - accuracy: 0.4236 - val_loss: 1.7204 - val_accuracy: 0.3880\n","Epoch 152/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.6331 - accuracy: 0.4300 - val_loss: 1.6767 - val_accuracy: 0.4015\n","Epoch 153/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6332 - accuracy: 0.4319 - val_loss: 1.6784 - val_accuracy: 0.4235\n","Epoch 154/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6325 - accuracy: 0.4274 - val_loss: 1.7110 - val_accuracy: 0.4165\n","Epoch 155/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6310 - accuracy: 0.4283 - val_loss: 1.7411 - val_accuracy: 0.3740\n","Epoch 156/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6285 - accuracy: 0.4283 - val_loss: 1.6633 - val_accuracy: 0.4285\n","Epoch 157/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6255 - accuracy: 0.4297 - val_loss: 1.7863 - val_accuracy: 0.3610\n","Epoch 158/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6263 - accuracy: 0.4333 - val_loss: 1.6906 - val_accuracy: 0.4030\n","Epoch 159/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6227 - accuracy: 0.4346 - val_loss: 1.7164 - val_accuracy: 0.4200\n","Epoch 160/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6191 - accuracy: 0.4362 - val_loss: 1.6694 - val_accuracy: 0.4075\n","Epoch 161/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6206 - accuracy: 0.4322 - val_loss: 1.7408 - val_accuracy: 0.3865\n","Epoch 162/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6199 - accuracy: 0.4308 - val_loss: 1.6877 - val_accuracy: 0.3990\n","Epoch 163/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6151 - accuracy: 0.4339 - val_loss: 1.7702 - val_accuracy: 0.3810\n","Epoch 164/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6171 - accuracy: 0.4359 - val_loss: 1.6867 - val_accuracy: 0.4005\n","Epoch 165/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6149 - accuracy: 0.4329 - val_loss: 1.6694 - val_accuracy: 0.4200\n","Epoch 166/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6113 - accuracy: 0.4354 - val_loss: 1.7204 - val_accuracy: 0.3955\n","Epoch 167/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6087 - accuracy: 0.4393 - val_loss: 1.6485 - val_accuracy: 0.4300\n","Epoch 168/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6081 - accuracy: 0.4371 - val_loss: 1.6879 - val_accuracy: 0.3990\n","Epoch 169/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.6048 - accuracy: 0.4373 - val_loss: 1.7010 - val_accuracy: 0.4190\n","Epoch 170/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6068 - accuracy: 0.4409 - val_loss: 1.6487 - val_accuracy: 0.4200\n","Epoch 171/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6031 - accuracy: 0.4413 - val_loss: 1.6839 - val_accuracy: 0.4040\n","Epoch 172/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.6042 - accuracy: 0.4400 - val_loss: 1.6458 - val_accuracy: 0.4235\n","Epoch 173/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.6000 - accuracy: 0.4412 - val_loss: 1.6525 - val_accuracy: 0.4130\n","Epoch 174/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5970 - accuracy: 0.4411 - val_loss: 1.6724 - val_accuracy: 0.4025\n","Epoch 175/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5973 - accuracy: 0.4388 - val_loss: 1.6913 - val_accuracy: 0.4085\n","Epoch 176/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5939 - accuracy: 0.4401 - val_loss: 1.6429 - val_accuracy: 0.4330\n","Epoch 177/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5928 - accuracy: 0.4443 - val_loss: 1.6453 - val_accuracy: 0.4165\n","Epoch 178/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5951 - accuracy: 0.4453 - val_loss: 1.6465 - val_accuracy: 0.4260\n","Epoch 179/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5895 - accuracy: 0.4430 - val_loss: 1.6479 - val_accuracy: 0.4270\n","Epoch 180/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5919 - accuracy: 0.4452 - val_loss: 1.6882 - val_accuracy: 0.4075\n","Epoch 181/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5872 - accuracy: 0.4441 - val_loss: 1.6690 - val_accuracy: 0.4260\n","Epoch 182/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5857 - accuracy: 0.4468 - val_loss: 1.6377 - val_accuracy: 0.4370\n","Epoch 183/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5834 - accuracy: 0.4462 - val_loss: 1.6316 - val_accuracy: 0.4235\n","Epoch 184/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5862 - accuracy: 0.4474 - val_loss: 1.6336 - val_accuracy: 0.4455\n","Epoch 185/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5820 - accuracy: 0.4482 - val_loss: 1.6831 - val_accuracy: 0.4025\n","Epoch 186/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5797 - accuracy: 0.4488 - val_loss: 1.6991 - val_accuracy: 0.3980\n","Epoch 187/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5791 - accuracy: 0.4473 - val_loss: 1.6981 - val_accuracy: 0.3850\n","Epoch 188/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5786 - accuracy: 0.4490 - val_loss: 1.6444 - val_accuracy: 0.4270\n","Epoch 189/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5755 - accuracy: 0.4519 - val_loss: 1.6571 - val_accuracy: 0.4215\n","Epoch 190/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5756 - accuracy: 0.4472 - val_loss: 1.6422 - val_accuracy: 0.4270\n","Epoch 191/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5744 - accuracy: 0.4514 - val_loss: 1.6398 - val_accuracy: 0.4145\n","Epoch 192/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5711 - accuracy: 0.4541 - val_loss: 1.6736 - val_accuracy: 0.4110\n","Epoch 193/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5745 - accuracy: 0.4522 - val_loss: 1.6402 - val_accuracy: 0.4185\n","Epoch 194/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5672 - accuracy: 0.4531 - val_loss: 1.6302 - val_accuracy: 0.4440\n","Epoch 195/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5679 - accuracy: 0.4537 - val_loss: 1.6753 - val_accuracy: 0.4065\n","Epoch 196/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5661 - accuracy: 0.4521 - val_loss: 1.7015 - val_accuracy: 0.3925\n","Epoch 197/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5628 - accuracy: 0.4556 - val_loss: 1.6434 - val_accuracy: 0.4270\n","Epoch 198/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5627 - accuracy: 0.4538 - val_loss: 1.7963 - val_accuracy: 0.3900\n","Epoch 199/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5638 - accuracy: 0.4546 - val_loss: 1.6327 - val_accuracy: 0.4445\n","Epoch 200/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5609 - accuracy: 0.4594 - val_loss: 1.6639 - val_accuracy: 0.4345\n","Epoch 201/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5582 - accuracy: 0.4559 - val_loss: 1.6060 - val_accuracy: 0.4415\n","Epoch 202/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5591 - accuracy: 0.4574 - val_loss: 1.6630 - val_accuracy: 0.4165\n","Epoch 203/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5559 - accuracy: 0.4546 - val_loss: 1.6207 - val_accuracy: 0.4450\n","Epoch 204/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5542 - accuracy: 0.4557 - val_loss: 2.0574 - val_accuracy: 0.3170\n","Epoch 205/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5595 - accuracy: 0.4560 - val_loss: 1.6339 - val_accuracy: 0.4450\n","Epoch 206/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5540 - accuracy: 0.4558 - val_loss: 1.6077 - val_accuracy: 0.4495\n","Epoch 207/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5506 - accuracy: 0.4619 - val_loss: 1.6150 - val_accuracy: 0.4365\n","Epoch 208/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5481 - accuracy: 0.4585 - val_loss: 1.6293 - val_accuracy: 0.4325\n","Epoch 209/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5475 - accuracy: 0.4601 - val_loss: 1.6098 - val_accuracy: 0.4320\n","Epoch 210/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5429 - accuracy: 0.4628 - val_loss: 1.6178 - val_accuracy: 0.4325\n","Epoch 211/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5452 - accuracy: 0.4620 - val_loss: 1.7336 - val_accuracy: 0.3955\n","Epoch 212/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5438 - accuracy: 0.4626 - val_loss: 1.6252 - val_accuracy: 0.4190\n","Epoch 213/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5396 - accuracy: 0.4629 - val_loss: 1.6893 - val_accuracy: 0.3940\n","Epoch 214/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5431 - accuracy: 0.4643 - val_loss: 1.6342 - val_accuracy: 0.4250\n","Epoch 215/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5393 - accuracy: 0.4602 - val_loss: 1.5876 - val_accuracy: 0.4405\n","Epoch 216/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5356 - accuracy: 0.4631 - val_loss: 1.6265 - val_accuracy: 0.4420\n","Epoch 217/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5351 - accuracy: 0.4679 - val_loss: 1.5932 - val_accuracy: 0.4425\n","Epoch 218/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5333 - accuracy: 0.4620 - val_loss: 1.5899 - val_accuracy: 0.4380\n","Epoch 219/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5313 - accuracy: 0.4659 - val_loss: 1.6075 - val_accuracy: 0.4300\n","Epoch 220/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5286 - accuracy: 0.4721 - val_loss: 1.5992 - val_accuracy: 0.4445\n","Epoch 221/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5290 - accuracy: 0.4651 - val_loss: 1.6396 - val_accuracy: 0.4210\n","Epoch 222/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5303 - accuracy: 0.4665 - val_loss: 1.6077 - val_accuracy: 0.4310\n","Epoch 223/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5270 - accuracy: 0.4643 - val_loss: 1.6361 - val_accuracy: 0.4310\n","Epoch 224/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5276 - accuracy: 0.4656 - val_loss: 1.5997 - val_accuracy: 0.4565\n","Epoch 225/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5253 - accuracy: 0.4677 - val_loss: 1.9746 - val_accuracy: 0.3350\n","Epoch 226/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5262 - accuracy: 0.4699 - val_loss: 1.6053 - val_accuracy: 0.4270\n","Epoch 227/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5208 - accuracy: 0.4708 - val_loss: 1.5830 - val_accuracy: 0.4405\n","Epoch 228/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5221 - accuracy: 0.4708 - val_loss: 1.6425 - val_accuracy: 0.4130\n","Epoch 229/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5209 - accuracy: 0.4674 - val_loss: 1.6946 - val_accuracy: 0.4110\n","Epoch 230/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5171 - accuracy: 0.4720 - val_loss: 1.7153 - val_accuracy: 0.3915\n","Epoch 231/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5179 - accuracy: 0.4711 - val_loss: 1.6039 - val_accuracy: 0.4300\n","Epoch 232/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.5153 - accuracy: 0.4726 - val_loss: 1.6439 - val_accuracy: 0.4405\n","Epoch 233/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5167 - accuracy: 0.4707 - val_loss: 1.5934 - val_accuracy: 0.4420\n","Epoch 234/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5147 - accuracy: 0.4703 - val_loss: 1.6042 - val_accuracy: 0.4575\n","Epoch 235/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5064 - accuracy: 0.4733 - val_loss: 1.5890 - val_accuracy: 0.4505\n","Epoch 236/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5093 - accuracy: 0.4718 - val_loss: 1.6304 - val_accuracy: 0.4280\n","Epoch 237/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5064 - accuracy: 0.4745 - val_loss: 1.6909 - val_accuracy: 0.3930\n","Epoch 238/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5091 - accuracy: 0.4732 - val_loss: 1.6640 - val_accuracy: 0.4385\n","Epoch 239/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5070 - accuracy: 0.4728 - val_loss: 1.6550 - val_accuracy: 0.4155\n","Epoch 240/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5042 - accuracy: 0.4753 - val_loss: 1.5948 - val_accuracy: 0.4540\n","Epoch 241/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5048 - accuracy: 0.4796 - val_loss: 1.7333 - val_accuracy: 0.3890\n","Epoch 242/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.5008 - accuracy: 0.4783 - val_loss: 1.6148 - val_accuracy: 0.4405\n","Epoch 243/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.5013 - accuracy: 0.4745 - val_loss: 1.5777 - val_accuracy: 0.4590\n","Epoch 244/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.5019 - accuracy: 0.4736 - val_loss: 1.5653 - val_accuracy: 0.4665\n","Epoch 245/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4964 - accuracy: 0.4736 - val_loss: 1.6012 - val_accuracy: 0.4455\n","Epoch 246/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4978 - accuracy: 0.4798 - val_loss: 1.5569 - val_accuracy: 0.4670\n","Epoch 247/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4958 - accuracy: 0.4764 - val_loss: 1.6729 - val_accuracy: 0.4295\n","Epoch 248/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4962 - accuracy: 0.4800 - val_loss: 1.6018 - val_accuracy: 0.4470\n","Epoch 249/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4943 - accuracy: 0.4764 - val_loss: 1.5863 - val_accuracy: 0.4575\n","Epoch 250/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4965 - accuracy: 0.4787 - val_loss: 1.7876 - val_accuracy: 0.3755\n","Epoch 251/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4951 - accuracy: 0.4769 - val_loss: 1.5848 - val_accuracy: 0.4540\n","Epoch 252/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4863 - accuracy: 0.4816 - val_loss: 1.6330 - val_accuracy: 0.4245\n","Epoch 253/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4874 - accuracy: 0.4799 - val_loss: 1.5654 - val_accuracy: 0.4595\n","Epoch 254/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4865 - accuracy: 0.4802 - val_loss: 1.6868 - val_accuracy: 0.4010\n","Epoch 255/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4856 - accuracy: 0.4850 - val_loss: 1.6920 - val_accuracy: 0.4325\n","Epoch 256/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4827 - accuracy: 0.4836 - val_loss: 1.6328 - val_accuracy: 0.4450\n","Epoch 257/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4815 - accuracy: 0.4829 - val_loss: 1.9283 - val_accuracy: 0.3595\n","Epoch 258/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4831 - accuracy: 0.4849 - val_loss: 1.5684 - val_accuracy: 0.4695\n","Epoch 259/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4760 - accuracy: 0.4877 - val_loss: 1.5874 - val_accuracy: 0.4410\n","Epoch 260/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4798 - accuracy: 0.4821 - val_loss: 1.6234 - val_accuracy: 0.4370\n","Epoch 261/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4763 - accuracy: 0.4813 - val_loss: 1.6313 - val_accuracy: 0.4330\n","Epoch 262/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4822 - accuracy: 0.4800 - val_loss: 1.5640 - val_accuracy: 0.4635\n","Epoch 263/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4759 - accuracy: 0.4851 - val_loss: 1.5647 - val_accuracy: 0.4645\n","Epoch 264/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4738 - accuracy: 0.4845 - val_loss: 1.6696 - val_accuracy: 0.4275\n","Epoch 265/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4743 - accuracy: 0.4902 - val_loss: 1.6051 - val_accuracy: 0.4370\n","Epoch 266/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4717 - accuracy: 0.4858 - val_loss: 1.5737 - val_accuracy: 0.4565\n","Epoch 267/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4707 - accuracy: 0.4911 - val_loss: 1.7733 - val_accuracy: 0.3865\n","Epoch 268/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4666 - accuracy: 0.4855 - val_loss: 1.5811 - val_accuracy: 0.4500\n","Epoch 269/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4685 - accuracy: 0.4865 - val_loss: 1.5445 - val_accuracy: 0.4615\n","Epoch 270/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4664 - accuracy: 0.4881 - val_loss: 1.6140 - val_accuracy: 0.4315\n","Epoch 271/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4687 - accuracy: 0.4870 - val_loss: 1.6059 - val_accuracy: 0.4445\n","Epoch 272/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4637 - accuracy: 0.4911 - val_loss: 1.6164 - val_accuracy: 0.4275\n","Epoch 273/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4605 - accuracy: 0.4917 - val_loss: 1.5811 - val_accuracy: 0.4475\n","Epoch 274/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4601 - accuracy: 0.4941 - val_loss: 1.5422 - val_accuracy: 0.4685\n","Epoch 275/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4593 - accuracy: 0.4944 - val_loss: 1.5987 - val_accuracy: 0.4335\n","Epoch 276/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4593 - accuracy: 0.4938 - val_loss: 1.5419 - val_accuracy: 0.4745\n","Epoch 277/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4574 - accuracy: 0.4891 - val_loss: 1.5725 - val_accuracy: 0.4560\n","Epoch 278/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4585 - accuracy: 0.4909 - val_loss: 1.5628 - val_accuracy: 0.4760\n","Epoch 279/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4512 - accuracy: 0.4908 - val_loss: 1.6898 - val_accuracy: 0.4130\n","Epoch 280/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4550 - accuracy: 0.4940 - val_loss: 1.5926 - val_accuracy: 0.4505\n","Epoch 281/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4483 - accuracy: 0.4962 - val_loss: 1.6357 - val_accuracy: 0.4345\n","Epoch 282/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4524 - accuracy: 0.4932 - val_loss: 1.6192 - val_accuracy: 0.4480\n","Epoch 283/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4543 - accuracy: 0.4938 - val_loss: 1.6328 - val_accuracy: 0.4205\n","Epoch 284/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4512 - accuracy: 0.4940 - val_loss: 1.6443 - val_accuracy: 0.4400\n","Epoch 285/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4445 - accuracy: 0.4954 - val_loss: 1.6214 - val_accuracy: 0.4455\n","Epoch 286/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4450 - accuracy: 0.4938 - val_loss: 1.6484 - val_accuracy: 0.4155\n","Epoch 287/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4470 - accuracy: 0.4934 - val_loss: 1.5335 - val_accuracy: 0.4650\n","Epoch 288/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4471 - accuracy: 0.4962 - val_loss: 1.6381 - val_accuracy: 0.4320\n","Epoch 289/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4444 - accuracy: 0.4967 - val_loss: 1.6078 - val_accuracy: 0.4425\n","Epoch 290/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4417 - accuracy: 0.4977 - val_loss: 1.5447 - val_accuracy: 0.4630\n","Epoch 291/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4378 - accuracy: 0.5017 - val_loss: 1.6170 - val_accuracy: 0.4340\n","Epoch 292/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4396 - accuracy: 0.5015 - val_loss: 1.9264 - val_accuracy: 0.3510\n","Epoch 293/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4456 - accuracy: 0.5006 - val_loss: 1.7230 - val_accuracy: 0.4130\n","Epoch 294/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4395 - accuracy: 0.4978 - val_loss: 1.5818 - val_accuracy: 0.4475\n","Epoch 295/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4351 - accuracy: 0.4974 - val_loss: 1.5555 - val_accuracy: 0.4580\n","Epoch 296/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4335 - accuracy: 0.5001 - val_loss: 1.5343 - val_accuracy: 0.4665\n","Epoch 297/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4337 - accuracy: 0.4992 - val_loss: 1.7602 - val_accuracy: 0.3935\n","Epoch 298/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4307 - accuracy: 0.5042 - val_loss: 1.6450 - val_accuracy: 0.4355\n","Epoch 299/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4300 - accuracy: 0.4998 - val_loss: 1.7500 - val_accuracy: 0.3940\n","Epoch 300/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4302 - accuracy: 0.5055 - val_loss: 1.5715 - val_accuracy: 0.4760\n","Epoch 301/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4294 - accuracy: 0.5035 - val_loss: 1.6457 - val_accuracy: 0.4290\n","Epoch 302/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4314 - accuracy: 0.5035 - val_loss: 1.6795 - val_accuracy: 0.4170\n","Epoch 303/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4249 - accuracy: 0.5024 - val_loss: 1.6072 - val_accuracy: 0.4395\n","Epoch 304/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4210 - accuracy: 0.5036 - val_loss: 1.5973 - val_accuracy: 0.4270\n","Epoch 305/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4198 - accuracy: 0.5023 - val_loss: 1.6037 - val_accuracy: 0.4405\n","Epoch 306/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4257 - accuracy: 0.5036 - val_loss: 1.5646 - val_accuracy: 0.4540\n","Epoch 307/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4200 - accuracy: 0.5057 - val_loss: 1.7271 - val_accuracy: 0.4050\n","Epoch 308/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4239 - accuracy: 0.5055 - val_loss: 1.6058 - val_accuracy: 0.4390\n","Epoch 309/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4223 - accuracy: 0.5069 - val_loss: 1.6372 - val_accuracy: 0.4465\n","Epoch 310/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4184 - accuracy: 0.5031 - val_loss: 1.7704 - val_accuracy: 0.3975\n","Epoch 311/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.4219 - accuracy: 0.5045 - val_loss: 1.5274 - val_accuracy: 0.4675\n","Epoch 312/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4134 - accuracy: 0.5042 - val_loss: 1.5300 - val_accuracy: 0.4670\n","Epoch 313/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4146 - accuracy: 0.5074 - val_loss: 1.5064 - val_accuracy: 0.4900\n","Epoch 314/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4105 - accuracy: 0.5081 - val_loss: 1.5219 - val_accuracy: 0.4850\n","Epoch 315/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4118 - accuracy: 0.5082 - val_loss: 1.6279 - val_accuracy: 0.4365\n","Epoch 316/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4111 - accuracy: 0.5069 - val_loss: 1.4978 - val_accuracy: 0.4875\n","Epoch 317/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4076 - accuracy: 0.5093 - val_loss: 1.5537 - val_accuracy: 0.4590\n","Epoch 318/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4080 - accuracy: 0.5113 - val_loss: 1.7865 - val_accuracy: 0.3915\n","Epoch 319/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4055 - accuracy: 0.5104 - val_loss: 1.5789 - val_accuracy: 0.4375\n","Epoch 320/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4066 - accuracy: 0.5062 - val_loss: 1.5001 - val_accuracy: 0.4785\n","Epoch 321/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4006 - accuracy: 0.5127 - val_loss: 1.4980 - val_accuracy: 0.4845\n","Epoch 322/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4053 - accuracy: 0.5085 - val_loss: 1.6194 - val_accuracy: 0.4415\n","Epoch 323/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4044 - accuracy: 0.5116 - val_loss: 1.5632 - val_accuracy: 0.4570\n","Epoch 324/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4027 - accuracy: 0.5098 - val_loss: 1.5829 - val_accuracy: 0.4440\n","Epoch 325/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4018 - accuracy: 0.5102 - val_loss: 1.8158 - val_accuracy: 0.3790\n","Epoch 326/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4052 - accuracy: 0.5110 - val_loss: 1.5605 - val_accuracy: 0.4625\n","Epoch 327/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3972 - accuracy: 0.5146 - val_loss: 1.5634 - val_accuracy: 0.4645\n","Epoch 328/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.4006 - accuracy: 0.5109 - val_loss: 1.4912 - val_accuracy: 0.4845\n","Epoch 329/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3947 - accuracy: 0.5165 - val_loss: 1.6403 - val_accuracy: 0.4245\n","Epoch 330/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3994 - accuracy: 0.5134 - val_loss: 1.6922 - val_accuracy: 0.4270\n","Epoch 331/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.4015 - accuracy: 0.5158 - val_loss: 1.5762 - val_accuracy: 0.4750\n","Epoch 332/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3938 - accuracy: 0.5132 - val_loss: 1.5665 - val_accuracy: 0.4530\n","Epoch 333/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3919 - accuracy: 0.5153 - val_loss: 1.5366 - val_accuracy: 0.4705\n","Epoch 334/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3923 - accuracy: 0.5154 - val_loss: 1.7745 - val_accuracy: 0.3940\n","Epoch 335/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3927 - accuracy: 0.5153 - val_loss: 1.5798 - val_accuracy: 0.4675\n","Epoch 336/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3880 - accuracy: 0.5121 - val_loss: 1.6761 - val_accuracy: 0.4315\n","Epoch 337/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3853 - accuracy: 0.5178 - val_loss: 1.5111 - val_accuracy: 0.4785\n","Epoch 338/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3849 - accuracy: 0.5184 - val_loss: 1.5504 - val_accuracy: 0.4685\n","Epoch 339/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3888 - accuracy: 0.5170 - val_loss: 1.5043 - val_accuracy: 0.4805\n","Epoch 340/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3854 - accuracy: 0.5192 - val_loss: 1.5497 - val_accuracy: 0.4645\n","Epoch 341/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3835 - accuracy: 0.5187 - val_loss: 1.4992 - val_accuracy: 0.4765\n","Epoch 342/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3831 - accuracy: 0.5198 - val_loss: 1.5677 - val_accuracy: 0.4635\n","Epoch 343/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3791 - accuracy: 0.5201 - val_loss: 1.7600 - val_accuracy: 0.4075\n","Epoch 344/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3898 - accuracy: 0.5118 - val_loss: 1.5504 - val_accuracy: 0.4815\n","Epoch 345/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3760 - accuracy: 0.5213 - val_loss: 1.5080 - val_accuracy: 0.4745\n","Epoch 346/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3755 - accuracy: 0.5223 - val_loss: 1.5868 - val_accuracy: 0.4670\n","Epoch 347/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3785 - accuracy: 0.5219 - val_loss: 1.5305 - val_accuracy: 0.4800\n","Epoch 348/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3761 - accuracy: 0.5206 - val_loss: 1.5239 - val_accuracy: 0.4710\n","Epoch 349/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3708 - accuracy: 0.5283 - val_loss: 1.5114 - val_accuracy: 0.4875\n","Epoch 350/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3737 - accuracy: 0.5200 - val_loss: 1.5244 - val_accuracy: 0.4720\n","Epoch 351/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3706 - accuracy: 0.5221 - val_loss: 1.6192 - val_accuracy: 0.4345\n","Epoch 352/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3712 - accuracy: 0.5219 - val_loss: 1.5389 - val_accuracy: 0.4685\n","Epoch 353/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3699 - accuracy: 0.5262 - val_loss: 1.5019 - val_accuracy: 0.4900\n","Epoch 354/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3685 - accuracy: 0.5252 - val_loss: 1.4792 - val_accuracy: 0.4905\n","Epoch 355/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3664 - accuracy: 0.5280 - val_loss: 1.5311 - val_accuracy: 0.4705\n","Epoch 356/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3639 - accuracy: 0.5269 - val_loss: 1.4948 - val_accuracy: 0.4800\n","Epoch 357/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3649 - accuracy: 0.5254 - val_loss: 1.5643 - val_accuracy: 0.4435\n","Epoch 358/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3680 - accuracy: 0.5258 - val_loss: 1.5271 - val_accuracy: 0.4635\n","Epoch 359/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3578 - accuracy: 0.5269 - val_loss: 1.5306 - val_accuracy: 0.4675\n","Epoch 360/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3655 - accuracy: 0.5228 - val_loss: 1.5230 - val_accuracy: 0.4900\n","Epoch 361/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3615 - accuracy: 0.5286 - val_loss: 1.5350 - val_accuracy: 0.4550\n","Epoch 362/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3567 - accuracy: 0.5249 - val_loss: 1.5283 - val_accuracy: 0.4885\n","Epoch 363/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3605 - accuracy: 0.5254 - val_loss: 1.7358 - val_accuracy: 0.4270\n","Epoch 364/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3640 - accuracy: 0.5291 - val_loss: 1.5238 - val_accuracy: 0.4865\n","Epoch 365/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3581 - accuracy: 0.5292 - val_loss: 1.8450 - val_accuracy: 0.3915\n","Epoch 366/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3613 - accuracy: 0.5255 - val_loss: 1.5056 - val_accuracy: 0.4795\n","Epoch 367/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3539 - accuracy: 0.5322 - val_loss: 1.6644 - val_accuracy: 0.4300\n","Epoch 368/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3589 - accuracy: 0.5293 - val_loss: 1.5520 - val_accuracy: 0.4845\n","Epoch 369/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3566 - accuracy: 0.5261 - val_loss: 1.4711 - val_accuracy: 0.5050\n","Epoch 370/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3502 - accuracy: 0.5306 - val_loss: 1.4688 - val_accuracy: 0.4860\n","Epoch 371/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3493 - accuracy: 0.5352 - val_loss: 1.5518 - val_accuracy: 0.4665\n","Epoch 372/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3556 - accuracy: 0.5306 - val_loss: 1.5976 - val_accuracy: 0.4415\n","Epoch 373/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3546 - accuracy: 0.5293 - val_loss: 1.4950 - val_accuracy: 0.4925\n","Epoch 374/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3453 - accuracy: 0.5320 - val_loss: 1.6070 - val_accuracy: 0.4555\n","Epoch 375/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3492 - accuracy: 0.5319 - val_loss: 1.5171 - val_accuracy: 0.4835\n","Epoch 376/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3463 - accuracy: 0.5335 - val_loss: 1.5059 - val_accuracy: 0.4655\n","Epoch 377/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3454 - accuracy: 0.5377 - val_loss: 1.4821 - val_accuracy: 0.4995\n","Epoch 378/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3443 - accuracy: 0.5312 - val_loss: 1.7118 - val_accuracy: 0.4390\n","Epoch 379/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3467 - accuracy: 0.5325 - val_loss: 1.6671 - val_accuracy: 0.4240\n","Epoch 380/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3436 - accuracy: 0.5332 - val_loss: 1.4628 - val_accuracy: 0.4970\n","Epoch 381/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3469 - accuracy: 0.5331 - val_loss: 1.5199 - val_accuracy: 0.4795\n","Epoch 382/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3402 - accuracy: 0.5384 - val_loss: 1.4714 - val_accuracy: 0.4870\n","Epoch 383/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3408 - accuracy: 0.5331 - val_loss: 1.6354 - val_accuracy: 0.4330\n","Epoch 384/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3387 - accuracy: 0.5354 - val_loss: 1.7666 - val_accuracy: 0.4045\n","Epoch 385/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3387 - accuracy: 0.5367 - val_loss: 1.5045 - val_accuracy: 0.4735\n","Epoch 386/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3322 - accuracy: 0.5354 - val_loss: 1.4671 - val_accuracy: 0.5070\n","Epoch 387/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3386 - accuracy: 0.5342 - val_loss: 1.5563 - val_accuracy: 0.4520\n","Epoch 388/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3319 - accuracy: 0.5356 - val_loss: 1.4816 - val_accuracy: 0.4765\n","Epoch 389/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3358 - accuracy: 0.5366 - val_loss: 1.4988 - val_accuracy: 0.4750\n","Epoch 390/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3284 - accuracy: 0.5366 - val_loss: 1.4700 - val_accuracy: 0.4865\n","Epoch 391/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3280 - accuracy: 0.5394 - val_loss: 1.5721 - val_accuracy: 0.4475\n","Epoch 392/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3314 - accuracy: 0.5350 - val_loss: 1.7834 - val_accuracy: 0.3870\n","Epoch 393/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3347 - accuracy: 0.5385 - val_loss: 1.5464 - val_accuracy: 0.4590\n","Epoch 394/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3287 - accuracy: 0.5365 - val_loss: 1.5070 - val_accuracy: 0.4870\n","Epoch 395/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3272 - accuracy: 0.5343 - val_loss: 1.4891 - val_accuracy: 0.4775\n","Epoch 396/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3254 - accuracy: 0.5358 - val_loss: 1.4950 - val_accuracy: 0.4815\n","Epoch 397/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3268 - accuracy: 0.5390 - val_loss: 1.4853 - val_accuracy: 0.4900\n","Epoch 398/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3243 - accuracy: 0.5411 - val_loss: 1.5698 - val_accuracy: 0.4580\n","Epoch 399/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3203 - accuracy: 0.5403 - val_loss: 1.6810 - val_accuracy: 0.4075\n","Epoch 400/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3283 - accuracy: 0.5398 - val_loss: 1.6880 - val_accuracy: 0.4185\n","Epoch 401/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3293 - accuracy: 0.5371 - val_loss: 1.5068 - val_accuracy: 0.4910\n","Epoch 402/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3187 - accuracy: 0.5434 - val_loss: 1.5224 - val_accuracy: 0.4840\n","Epoch 403/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3211 - accuracy: 0.5420 - val_loss: 1.4937 - val_accuracy: 0.4780\n","Epoch 404/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3168 - accuracy: 0.5407 - val_loss: 1.5709 - val_accuracy: 0.4525\n","Epoch 405/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3177 - accuracy: 0.5420 - val_loss: 1.5577 - val_accuracy: 0.4850\n","Epoch 406/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3172 - accuracy: 0.5406 - val_loss: 1.5066 - val_accuracy: 0.4720\n","Epoch 407/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3181 - accuracy: 0.5421 - val_loss: 1.5042 - val_accuracy: 0.4705\n","Epoch 408/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3136 - accuracy: 0.5461 - val_loss: 1.4932 - val_accuracy: 0.4750\n","Epoch 409/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3135 - accuracy: 0.5441 - val_loss: 1.4747 - val_accuracy: 0.4830\n","Epoch 410/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3104 - accuracy: 0.5470 - val_loss: 1.7629 - val_accuracy: 0.4100\n","Epoch 411/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3133 - accuracy: 0.5426 - val_loss: 1.6193 - val_accuracy: 0.4720\n","Epoch 412/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3059 - accuracy: 0.5486 - val_loss: 1.5902 - val_accuracy: 0.4550\n","Epoch 413/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3109 - accuracy: 0.5453 - val_loss: 1.5208 - val_accuracy: 0.4915\n","Epoch 414/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3058 - accuracy: 0.5475 - val_loss: 1.5979 - val_accuracy: 0.4425\n","Epoch 415/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3040 - accuracy: 0.5480 - val_loss: 1.5187 - val_accuracy: 0.4640\n","Epoch 416/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3061 - accuracy: 0.5517 - val_loss: 1.6025 - val_accuracy: 0.4335\n","Epoch 417/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3037 - accuracy: 0.5481 - val_loss: 1.4888 - val_accuracy: 0.4940\n","Epoch 418/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3002 - accuracy: 0.5514 - val_loss: 1.4671 - val_accuracy: 0.4910\n","Epoch 419/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3030 - accuracy: 0.5507 - val_loss: 1.5871 - val_accuracy: 0.4720\n","Epoch 420/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3075 - accuracy: 0.5458 - val_loss: 1.5667 - val_accuracy: 0.4710\n","Epoch 421/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.3044 - accuracy: 0.5473 - val_loss: 1.4880 - val_accuracy: 0.4965\n","Epoch 422/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.3008 - accuracy: 0.5443 - val_loss: 1.5076 - val_accuracy: 0.4755\n","Epoch 423/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2949 - accuracy: 0.5493 - val_loss: 1.6983 - val_accuracy: 0.4145\n","Epoch 424/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.3006 - accuracy: 0.5505 - val_loss: 1.5000 - val_accuracy: 0.4760\n","Epoch 425/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2979 - accuracy: 0.5462 - val_loss: 1.4699 - val_accuracy: 0.4935\n","Epoch 426/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2976 - accuracy: 0.5479 - val_loss: 1.4757 - val_accuracy: 0.4975\n","Epoch 427/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2933 - accuracy: 0.5493 - val_loss: 1.5972 - val_accuracy: 0.4455\n","Epoch 428/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2923 - accuracy: 0.5506 - val_loss: 1.5247 - val_accuracy: 0.4805\n","Epoch 429/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2922 - accuracy: 0.5510 - val_loss: 1.5471 - val_accuracy: 0.4710\n","Epoch 430/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2940 - accuracy: 0.5477 - val_loss: 1.4798 - val_accuracy: 0.4950\n","Epoch 431/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2870 - accuracy: 0.5547 - val_loss: 1.4595 - val_accuracy: 0.5000\n","Epoch 432/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2917 - accuracy: 0.5521 - val_loss: 1.5201 - val_accuracy: 0.4730\n","Epoch 433/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2923 - accuracy: 0.5520 - val_loss: 1.7228 - val_accuracy: 0.4445\n","Epoch 434/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2908 - accuracy: 0.5494 - val_loss: 1.4925 - val_accuracy: 0.4920\n","Epoch 435/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.2894 - accuracy: 0.5521 - val_loss: 1.4918 - val_accuracy: 0.4975\n","Epoch 436/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2921 - accuracy: 0.5538 - val_loss: 1.4469 - val_accuracy: 0.4970\n","Epoch 437/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2818 - accuracy: 0.5572 - val_loss: 1.5999 - val_accuracy: 0.4620\n","Epoch 438/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2814 - accuracy: 0.5531 - val_loss: 1.5956 - val_accuracy: 0.4620\n","Epoch 439/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2877 - accuracy: 0.5550 - val_loss: 1.4964 - val_accuracy: 0.4830\n","Epoch 440/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2853 - accuracy: 0.5528 - val_loss: 1.6251 - val_accuracy: 0.4395\n","Epoch 441/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2838 - accuracy: 0.5508 - val_loss: 1.5117 - val_accuracy: 0.4755\n","Epoch 442/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2769 - accuracy: 0.5577 - val_loss: 1.4593 - val_accuracy: 0.4925\n","Epoch 443/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2815 - accuracy: 0.5547 - val_loss: 1.4911 - val_accuracy: 0.4900\n","Epoch 444/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2802 - accuracy: 0.5536 - val_loss: 1.8837 - val_accuracy: 0.3915\n","Epoch 445/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2872 - accuracy: 0.5523 - val_loss: 1.5825 - val_accuracy: 0.4600\n","Epoch 446/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2872 - accuracy: 0.5509 - val_loss: 1.4715 - val_accuracy: 0.5005\n","Epoch 447/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2741 - accuracy: 0.5556 - val_loss: 1.5157 - val_accuracy: 0.4885\n","Epoch 448/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2748 - accuracy: 0.5538 - val_loss: 1.4484 - val_accuracy: 0.5095\n","Epoch 449/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2758 - accuracy: 0.5583 - val_loss: 1.4400 - val_accuracy: 0.5030\n","Epoch 450/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2729 - accuracy: 0.5576 - val_loss: 1.7592 - val_accuracy: 0.4280\n","Epoch 451/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2867 - accuracy: 0.5557 - val_loss: 1.5322 - val_accuracy: 0.4710\n","Epoch 452/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2787 - accuracy: 0.5573 - val_loss: 1.5418 - val_accuracy: 0.4680\n","Epoch 453/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2723 - accuracy: 0.5569 - val_loss: 1.4599 - val_accuracy: 0.4995\n","Epoch 454/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2664 - accuracy: 0.5616 - val_loss: 1.9584 - val_accuracy: 0.3860\n","Epoch 455/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2700 - accuracy: 0.5602 - val_loss: 1.5748 - val_accuracy: 0.4590\n","Epoch 456/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2665 - accuracy: 0.5611 - val_loss: 1.4989 - val_accuracy: 0.4835\n","Epoch 457/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2657 - accuracy: 0.5601 - val_loss: 1.4501 - val_accuracy: 0.5010\n","Epoch 458/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2642 - accuracy: 0.5599 - val_loss: 1.5163 - val_accuracy: 0.4780\n","Epoch 459/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2652 - accuracy: 0.5625 - val_loss: 1.5554 - val_accuracy: 0.4630\n","Epoch 460/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2641 - accuracy: 0.5610 - val_loss: 1.5296 - val_accuracy: 0.4955\n","Epoch 461/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2645 - accuracy: 0.5625 - val_loss: 1.4878 - val_accuracy: 0.4880\n","Epoch 462/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2630 - accuracy: 0.5635 - val_loss: 1.4388 - val_accuracy: 0.5165\n","Epoch 463/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2651 - accuracy: 0.5640 - val_loss: 1.5868 - val_accuracy: 0.4545\n","Epoch 464/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2678 - accuracy: 0.5596 - val_loss: 1.4724 - val_accuracy: 0.4870\n","Epoch 465/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2576 - accuracy: 0.5642 - val_loss: 1.5189 - val_accuracy: 0.4695\n","Epoch 466/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2627 - accuracy: 0.5621 - val_loss: 1.4632 - val_accuracy: 0.4875\n","Epoch 467/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2568 - accuracy: 0.5601 - val_loss: 1.5162 - val_accuracy: 0.4720\n","Epoch 468/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2527 - accuracy: 0.5655 - val_loss: 1.6280 - val_accuracy: 0.4550\n","Epoch 469/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2592 - accuracy: 0.5630 - val_loss: 1.5104 - val_accuracy: 0.4730\n","Epoch 470/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2503 - accuracy: 0.5639 - val_loss: 1.5239 - val_accuracy: 0.4660\n","Epoch 471/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2519 - accuracy: 0.5683 - val_loss: 1.5076 - val_accuracy: 0.4900\n","Epoch 472/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2506 - accuracy: 0.5636 - val_loss: 1.5365 - val_accuracy: 0.4610\n","Epoch 473/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2529 - accuracy: 0.5640 - val_loss: 1.6151 - val_accuracy: 0.4385\n","Epoch 474/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2604 - accuracy: 0.5610 - val_loss: 1.8770 - val_accuracy: 0.4025\n","Epoch 475/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2516 - accuracy: 0.5640 - val_loss: 1.5849 - val_accuracy: 0.4505\n","Epoch 476/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2521 - accuracy: 0.5643 - val_loss: 1.5869 - val_accuracy: 0.4670\n","Epoch 477/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2486 - accuracy: 0.5647 - val_loss: 1.4799 - val_accuracy: 0.4915\n","Epoch 478/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2483 - accuracy: 0.5662 - val_loss: 1.4429 - val_accuracy: 0.5000\n","Epoch 479/1000\n","79/79 [==============================] - 0s 6ms/step - loss: 1.2443 - accuracy: 0.5694 - val_loss: 1.4404 - val_accuracy: 0.5020\n","Epoch 480/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2443 - accuracy: 0.5688 - val_loss: 1.5101 - val_accuracy: 0.4770\n","Epoch 481/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2436 - accuracy: 0.5666 - val_loss: 1.4661 - val_accuracy: 0.5095\n","Epoch 482/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2398 - accuracy: 0.5679 - val_loss: 1.8576 - val_accuracy: 0.3715\n","Epoch 483/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2455 - accuracy: 0.5659 - val_loss: 1.4447 - val_accuracy: 0.5070\n","Epoch 484/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2419 - accuracy: 0.5664 - val_loss: 1.4902 - val_accuracy: 0.4780\n","Epoch 485/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2434 - accuracy: 0.5663 - val_loss: 1.5104 - val_accuracy: 0.4675\n","Epoch 486/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2352 - accuracy: 0.5723 - val_loss: 1.4315 - val_accuracy: 0.5110\n","Epoch 487/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2360 - accuracy: 0.5703 - val_loss: 1.4288 - val_accuracy: 0.5040\n","Epoch 488/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2353 - accuracy: 0.5700 - val_loss: 1.5766 - val_accuracy: 0.4590\n","Epoch 489/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2371 - accuracy: 0.5680 - val_loss: 1.4449 - val_accuracy: 0.5060\n","Epoch 490/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2305 - accuracy: 0.5750 - val_loss: 1.6414 - val_accuracy: 0.4330\n","Epoch 491/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2318 - accuracy: 0.5712 - val_loss: 1.4990 - val_accuracy: 0.4845\n","Epoch 492/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2337 - accuracy: 0.5672 - val_loss: 1.5002 - val_accuracy: 0.4900\n","Epoch 493/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2368 - accuracy: 0.5726 - val_loss: 1.4834 - val_accuracy: 0.4875\n","Epoch 494/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2302 - accuracy: 0.5739 - val_loss: 1.5087 - val_accuracy: 0.4795\n","Epoch 495/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2352 - accuracy: 0.5689 - val_loss: 1.5547 - val_accuracy: 0.4695\n","Epoch 496/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2302 - accuracy: 0.5714 - val_loss: 1.4976 - val_accuracy: 0.4810\n","Epoch 497/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2313 - accuracy: 0.5699 - val_loss: 1.5283 - val_accuracy: 0.4805\n","Epoch 498/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2272 - accuracy: 0.5733 - val_loss: 1.4883 - val_accuracy: 0.4810\n","Epoch 499/1000\n","79/79 [==============================] - 1s 6ms/step - loss: 1.2285 - accuracy: 0.5736 - val_loss: 1.6120 - val_accuracy: 0.4650\n","Epoch 500/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2253 - accuracy: 0.5742 - val_loss: 1.4983 - val_accuracy: 0.4870\n","Epoch 501/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2284 - accuracy: 0.5710 - val_loss: 1.4414 - val_accuracy: 0.5000\n","Epoch 502/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2224 - accuracy: 0.5758 - val_loss: 1.4606 - val_accuracy: 0.4885\n","Epoch 503/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2195 - accuracy: 0.5750 - val_loss: 1.5303 - val_accuracy: 0.4730\n","Epoch 504/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2231 - accuracy: 0.5737 - val_loss: 1.4412 - val_accuracy: 0.4980\n","Epoch 505/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2189 - accuracy: 0.5795 - val_loss: 1.5535 - val_accuracy: 0.4700\n","Epoch 506/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2191 - accuracy: 0.5749 - val_loss: 1.4748 - val_accuracy: 0.4980\n","Epoch 507/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2204 - accuracy: 0.5768 - val_loss: 1.5178 - val_accuracy: 0.4740\n","Epoch 508/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2216 - accuracy: 0.5775 - val_loss: 1.5710 - val_accuracy: 0.4555\n","Epoch 509/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2183 - accuracy: 0.5741 - val_loss: 1.4781 - val_accuracy: 0.4870\n","Epoch 510/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2188 - accuracy: 0.5772 - val_loss: 1.5122 - val_accuracy: 0.4710\n","Epoch 511/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2154 - accuracy: 0.5741 - val_loss: 1.4318 - val_accuracy: 0.5120\n","Epoch 512/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2147 - accuracy: 0.5804 - val_loss: 1.4307 - val_accuracy: 0.5045\n","Epoch 513/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2148 - accuracy: 0.5803 - val_loss: 1.4413 - val_accuracy: 0.4970\n","Epoch 514/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2101 - accuracy: 0.5798 - val_loss: 1.4435 - val_accuracy: 0.5025\n","Epoch 515/1000\n","79/79 [==============================] - 1s 7ms/step - loss: 1.2083 - accuracy: 0.5770 - val_loss: 1.5044 - val_accuracy: 0.4805\n","Epoch 516/1000\n"," 1/79 [..............................] - ETA: 0s - loss: 1.4894 - accuracy: 0.4609"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-42a3fdb42d07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m                 )\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-42a3fdb42d07>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mWandbCallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                 )\n\u001b[1;32m    102\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36mnew_v2\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcbk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcbks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0mset_wandb_attrs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mold_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mtraining_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morig_fit_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mold_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"09SC2-oh0Lgh"},"source":[""],"execution_count":null,"outputs":[]}]}