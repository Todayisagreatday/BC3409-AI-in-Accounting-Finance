{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import wandb\nfrom wandb.keras import WandbCallback\nimport os\nimport pickle\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models, optimizers, preprocessing, optimizers, callbacks\n\n# Function to load data file \ndef load_data(file):\n    with open(file, 'rb') as fo:\n        try:\n            samples = pickle.load(fo)\n        except UnicodeDecodeError:  # python 3.x\n            fo.seek(0)\n            samples = pickle.load(fo, encoding='latin1')\n\n    data, labels = samples['data'], samples['labels']\n\n    data = np.array(data, dtype=np.float32) / 255\n    labels = np.array(labels, dtype=np.int32)\n    return data, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load data and combine batches\nx_test, y_test = load_data('/kaggle/input/cifar10-python/cifar-10-batches-py/test_batch')\n\nx_train_1, y_train_1 = load_data('/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_1')\nx_train_2, y_train_2 = load_data('/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_2')\nx_train_3, y_train_3 = load_data('/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_3')\nx_train_4, y_train_4 = load_data('/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_4')\nx_train_5, y_train_5 = load_data('/kaggle/input/cifar10-python/cifar-10-batches-py/data_batch_5')\n\nx_train = np.concatenate((x_train_1, x_train_2, x_train_3, x_train_4, x_train_5))\ny_train = np.concatenate((y_train_1, y_train_2, y_train_3, y_train_4, y_train_5))\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Define model \ndef make_model(num_ch_c1, num_ch_c2):\n    \n    model = models.Sequential()\n    model.add(layers.Reshape(target_shape=(32, 32, 3), input_shape=(3072,)))\n    model.add(layers.Conv2D(num_ch_c1, kernel_size=9, activation='relu', input_shape=(None, None, 3), padding='valid'))\n    model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n    model.add(layers.Conv2D(num_ch_c2, kernel_size=5, activation='relu', padding='valid'))\n    model.add(layers.MaxPooling2D(pool_size=2, strides=2, padding='valid'))\n    model.add(layers.Flatten())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(300))\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(10, input_shape=(300,)))\n    return model\n\ndef main():\n    # Fix lucky seed!\n    seed = 7\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\n    # Hyperparameters\n    defaults=dict(\n    num_ch_c1 = 90, \n    num_ch_c2 = 40,\n    epochs = 1000,\n    batch_size = 128,\n    learning_rate = 0.001,\n    optimizer = 'SGD',\n    dropout_layer_1 = '0.5',\n    dropout_layer_2 = '0.5',\n    )\n    \n    # Initiate wandb project \n    wandb.init(config=defaults, resume=True, name='Full Dataset', project='NNA2 Test Runs')\n    config = wandb.config\n\n    # Call model and define loss function\n    model = make_model(config.num_ch_c1, config.num_ch_c2)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\n    # Choose optimizer\n    if(config.optimizer == 'SGD'):\n        SGD = optimizers.SGD(learning_rate=config.learning_rate)\n        opt = SGD\n    elif(config.optimizer == 'Adam'):\n        Adam = optimizers.Adam(learning_rate=config.learning_rate)\n        opt = Adam\n    else:\n        RMSprop = optimizers.RMSprop(learning_rate=config.learning_rate)\n        opt = RMSprop\n\n    # Compile and fit data\n    model.compile(optimizer=opt, loss=loss, metrics='accuracy')\n    model.fit(x_train, y_train,\n                batch_size=config.batch_size,\n                epochs=config.epochs,\n                validation_data=(x_test, y_test),\n                callbacks=[WandbCallback()]\n                )\n  \nif __name__ == '__main__':\n  main()\n  print('Program complete')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}